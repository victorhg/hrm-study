{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd58118",
   "metadata": {},
   "source": [
    "HRM Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62315096",
   "metadata": {},
   "source": [
    "load sudoku data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88af0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 81)\n",
      "(1000, 81)\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ _ _ 4 _ 9 _ 5    0| 7 3 2 8 4 6 9 1 5\n",
      "1| _ 8 _ _ _ 1 2 _ _    1| 4 8 9 5 3 1 2 7 6\n",
      "2| 5 _ _ 2 _ _ 3 4 _    2| 5 1 6 2 7 9 3 4 8\n",
      "3| _ 7 8 4 _ _ _ 2 _    3| 1 7 8 4 6 3 5 2 9\n",
      "4| _ _ _ _ _ _ _ _ _    4| 9 5 4 1 8 2 6 3 7\n",
      "5| 6 _ _ _ _ _ 4 8 1    5| 6 2 3 9 5 7 4 8 1\n",
      "6| _ _ _ 7 _ _ 8 _ _    6| 3 9 5 7 1 4 8 6 2\n",
      "7| _ 6 _ _ _ _ 7 _ _    7| 8 6 1 3 2 5 7 9 4\n",
      "8| _ _ _ 6 9 8 _ _ _    8| 2 4 7 6 9 8 1 5 3\n",
      "\n",
      "Statistics: 25 filled, 56 blank cells\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import pydantic \n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from dataset.sudoku import SudokuDataset\n",
    "\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "import dataset.sudoku as sudoku\n",
    "\n",
    "def load_sudoku_data(data_path: str, max_samples: int = 1000):\n",
    "    # Load the dictionary that was saved\n",
    "    data = np.load(data_path, allow_pickle=True).item()\n",
    " \n",
    "    puzzles = []\n",
    "    solutions = []\n",
    "\n",
    "    # Extract puzzles and solutions from the dictionary\n",
    "    for i in range(min(max_samples, len(data))):\n",
    "        if i in data:\n",
    "            puzzles.append(data[i][\"puzzle\"])\n",
    "            solutions.append(data[i][\"solution\"])\n",
    "\n",
    "    return np.array(puzzles), np.array(solutions)\n",
    "\n",
    "# presenting the data\n",
    "puzzles, solutions = load_sudoku_data(\"./data/sudoku_train.npy\")\n",
    "test_puzzles, test_solutions = load_sudoku_data(\"./data/sudoku_test.npy\")\n",
    "\n",
    "print(test_puzzles.shape)\n",
    "print(test_solutions.shape)\n",
    "\n",
    "sudoku.display_puzzle_pair(puzzles[0].reshape(9, 9), solutions[0].reshape(9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02fe839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrm import HRMConfig, HierarchicalReasoningModel, ModelConfig\n",
    "\n",
    "class HRMTrainer:\n",
    "    \"\"\"\n",
    "    Trainer class for the Hierarchical Reasoning Model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: HierarchicalReasoningModel, \n",
    "                 config=None, device=None):\n",
    "        \n",
    "        self.model = model\n",
    "        self.config = config or ModelConfig()\n",
    "        self.device = device or torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Training components\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.model.parameters()),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        \n",
    "        # Training state\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model_state = None\n",
    "        self.epochs_without_improvement = 0\n",
    "        \n",
    "        # Early stopping params\n",
    "        self.patience = 15\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    def _accuracy(self, logits: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "        # logits: (B, 81, C) targets: (B,81)\n",
    "        print(logits.shape, targets.shape)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        correct = (preds == targets).float().sum().item()\n",
    "        total = targets.numel()\n",
    "        return correct / total\n",
    "\n",
    "    # Replace your _run_epoch method with this corrected version\n",
    "    def _run_epoch(self, loader: DataLoader, train: bool = True):\n",
    "        \n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        total_batches = 0\n",
    "        \n",
    "        for batch in loader:\n",
    "            puzzles, solutions = batch[\"puzzle\"], batch[\"solution\"]\n",
    "            puzzles = puzzles.to(self.device).float()\n",
    "            solutions = solutions.to(self.device).long()\n",
    "            \n",
    "            # Debug shapes at each step\n",
    "            #print(f\"Batch {total_batches}: Input {puzzles.shape}, Target {solutions.shape}\")\n",
    "            \n",
    "            if train:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass - add unsqueeze to make input 3D\n",
    "            if puzzles.dim() == 2:\n",
    "                puzzles = puzzles.unsqueeze(-1)  # (B, 81) -> (B, 81, 1)\n",
    "            \n",
    "            model_output = self.model(puzzles)\n",
    "            #print(f\"Model output shape: {model_output.shape}\")\n",
    "\n",
    "            \n",
    "            # Calculate loss based on output dimensions\n",
    "            batch_size, seq_len, num_classes = model_output.shape\n",
    "\n",
    "            output_flat = model_output.view(-1, num_classes)  # (B*81, C)\n",
    "            solutions_flat = solutions.view(-1)               # (B*81,)\n",
    "            #print(f\"  Flattened: output {output_flat.shape}, target {solutions_flat.shape}\")\n",
    "            \n",
    "            loss = self.criterion(output_flat, solutions_flat)\n",
    "            \n",
    "            # FIX: Compare flattened predictions with flattened solutions\n",
    "            preds = output_flat.argmax(dim=-1)  # (B*81,)\n",
    "            acc = (preds == solutions_flat).float().mean().item()  # Both same shape now\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            total_batches += 1\n",
    "                \n",
    "        return epoch_loss / max(1, total_batches), epoch_acc / max(1, total_batches)\n",
    "\n",
    "    def train(self, train_dataset, val_dataset=None):\n",
    "        epochs = self.config.max_epochs\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size) if val_dataset is not None else None\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = self._run_epoch(train_loader, train=True)\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accuracies.append(train_acc)\n",
    "\n",
    "            if val_loader is not None:\n",
    "                with torch.no_grad():\n",
    "                    val_loss, val_acc = self._run_epoch(val_loader, train=False)\n",
    "                self.val_losses.append(val_loss)\n",
    "                self.val_accuracies.append(val_acc)\n",
    "                self.scheduler.step(val_loss)\n",
    "            else:\n",
    "                val_loss, val_acc = train_loss, train_acc  # fallback\n",
    "\n",
    "            improved = val_loss < self.best_val_loss - 1e-5\n",
    "            if improved:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_state = {\n",
    "                    'model': self.model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'val_loss': val_loss\n",
    "                }\n",
    "                self.epochs_without_improvement = 0\n",
    "            else:\n",
    "                self.epochs_without_improvement += 1\n",
    "\n",
    "            print(f\"Epoch {epoch:03d} | Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f} | LR {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            if self.epochs_without_improvement >= self.patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        # Save best checkpoint\n",
    "        if self.best_model_state is not None:\n",
    "            torch.save(self.best_model_state, 'results/best_model.pt')\n",
    "            print(f\"Best model (val_loss={self.best_model_state['val_loss']:.4f}) saved to results/best_model.pt\")\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        loader = DataLoader(dataset, batch_size=self.config.batch_size)\n",
    "        with torch.no_grad():\n",
    "            loss, acc = self._run_epoch(loader, train=False)\n",
    "        print(f\"Eval Loss {loss:.4f} Acc {acc:.4f}\")\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss 1.6376 Acc 0.3618 | Val Loss 1.5231 Acc 0.3971 | LR 1.00e-03\n",
      "Epoch 002 | Train Loss 1.5139 Acc 0.3965 | Val Loss 1.5023 Acc 0.4002 | LR 1.00e-03\n",
      "Epoch 002 | Train Loss 1.5139 Acc 0.3965 | Val Loss 1.5023 Acc 0.4002 | LR 1.00e-03\n",
      "Epoch 003 | Train Loss 1.5032 Acc 0.3996 | Val Loss 1.5004 Acc 0.3985 | LR 1.00e-03\n",
      "Epoch 003 | Train Loss 1.5032 Acc 0.3996 | Val Loss 1.5004 Acc 0.3985 | LR 1.00e-03\n",
      "Epoch 004 | Train Loss 1.5015 Acc 0.4001 | Val Loss 1.4957 Acc 0.3995 | LR 1.00e-03\n",
      "Epoch 004 | Train Loss 1.5015 Acc 0.4001 | Val Loss 1.4957 Acc 0.3995 | LR 1.00e-03\n",
      "Epoch 005 | Train Loss 1.5049 Acc 0.3985 | Val Loss 1.4980 Acc 0.4002 | LR 1.00e-03\n",
      "Epoch 005 | Train Loss 1.5049 Acc 0.3985 | Val Loss 1.4980 Acc 0.4002 | LR 1.00e-03\n",
      "Epoch 006 | Train Loss 1.4968 Acc 0.3998 | Val Loss 1.4895 Acc 0.4022 | LR 1.00e-03\n",
      "Epoch 006 | Train Loss 1.4968 Acc 0.3998 | Val Loss 1.4895 Acc 0.4022 | LR 1.00e-03\n",
      "Epoch 007 | Train Loss 1.4935 Acc 0.4005 | Val Loss 1.4884 Acc 0.4011 | LR 1.00e-03\n",
      "Epoch 007 | Train Loss 1.4935 Acc 0.4005 | Val Loss 1.4884 Acc 0.4011 | LR 1.00e-03\n",
      "Epoch 008 | Train Loss 1.4966 Acc 0.3988 | Val Loss 1.4972 Acc 0.3993 | LR 1.00e-03\n",
      "Epoch 008 | Train Loss 1.4966 Acc 0.3988 | Val Loss 1.4972 Acc 0.3993 | LR 1.00e-03\n",
      "Epoch 009 | Train Loss 1.4869 Acc 0.4022 | Val Loss 1.4854 Acc 0.4011 | LR 1.00e-03\n",
      "Epoch 009 | Train Loss 1.4869 Acc 0.4022 | Val Loss 1.4854 Acc 0.4011 | LR 1.00e-03\n",
      "Epoch 010 | Train Loss 1.4864 Acc 0.4030 | Val Loss 1.4932 Acc 0.3987 | LR 1.00e-03\n",
      "Epoch 010 | Train Loss 1.4864 Acc 0.4030 | Val Loss 1.4932 Acc 0.3987 | LR 1.00e-03\n",
      "Epoch 011 | Train Loss 1.4885 Acc 0.4029 | Val Loss 1.4853 Acc 0.4029 | LR 1.00e-03\n",
      "Epoch 011 | Train Loss 1.4885 Acc 0.4029 | Val Loss 1.4853 Acc 0.4029 | LR 1.00e-03\n",
      "Epoch 012 | Train Loss 1.4860 Acc 0.4025 | Val Loss 1.4844 Acc 0.4016 | LR 1.00e-03\n",
      "Epoch 012 | Train Loss 1.4860 Acc 0.4025 | Val Loss 1.4844 Acc 0.4016 | LR 1.00e-03\n",
      "Epoch 013 | Train Loss 1.4871 Acc 0.4017 | Val Loss 1.4864 Acc 0.4010 | LR 1.00e-03\n",
      "Epoch 013 | Train Loss 1.4871 Acc 0.4017 | Val Loss 1.4864 Acc 0.4010 | LR 1.00e-03\n",
      "Epoch 014 | Train Loss 1.4833 Acc 0.4053 | Val Loss 1.4895 Acc 0.4006 | LR 1.00e-03\n",
      "Epoch 014 | Train Loss 1.4833 Acc 0.4053 | Val Loss 1.4895 Acc 0.4006 | LR 1.00e-03\n",
      "Epoch 015 | Train Loss 1.4852 Acc 0.4035 | Val Loss 1.4835 Acc 0.4013 | LR 1.00e-03\n",
      "Epoch 015 | Train Loss 1.4852 Acc 0.4035 | Val Loss 1.4835 Acc 0.4013 | LR 1.00e-03\n",
      "Epoch 016 | Train Loss 1.4834 Acc 0.4026 | Val Loss 1.4828 Acc 0.4002 | LR 1.00e-03\n",
      "Epoch 016 | Train Loss 1.4834 Acc 0.4026 | Val Loss 1.4828 Acc 0.4002 | LR 1.00e-03\n",
      "Epoch 017 | Train Loss 1.4851 Acc 0.4038 | Val Loss 1.4965 Acc 0.4009 | LR 1.00e-03\n",
      "Epoch 017 | Train Loss 1.4851 Acc 0.4038 | Val Loss 1.4965 Acc 0.4009 | LR 1.00e-03\n",
      "Epoch 018 | Train Loss 1.4841 Acc 0.4032 | Val Loss 1.4858 Acc 0.4019 | LR 1.00e-03\n",
      "Epoch 018 | Train Loss 1.4841 Acc 0.4032 | Val Loss 1.4858 Acc 0.4019 | LR 1.00e-03\n",
      "Epoch 019 | Train Loss 1.4838 Acc 0.4027 | Val Loss 1.4950 Acc 0.3988 | LR 1.00e-03\n",
      "Epoch 019 | Train Loss 1.4838 Acc 0.4027 | Val Loss 1.4950 Acc 0.3988 | LR 1.00e-03\n",
      "Epoch 020 | Train Loss 1.4844 Acc 0.4042 | Val Loss 1.4923 Acc 0.4003 | LR 1.00e-03\n",
      "Best model (val_loss=1.4828) saved to results/best_model.pt\n",
      "Epoch 020 | Train Loss 1.4844 Acc 0.4042 | Val Loss 1.4923 Acc 0.4003 | LR 1.00e-03\n",
      "Best model (val_loss=1.4828) saved to results/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "hrm_config = HRMConfig(\n",
    "    input_dim=1,   # Each position has 1 feature (digit value) - input is (B, 81, 1)\n",
    "    output_dim=10, # 10 possible values (0-9) for each position\n",
    "    hidden_dim=512, # Reasonable hidden size\n",
    "    num_layers=4,\n",
    "    dropout=0.1,\n",
    "    N=2,  # Number of high-level cycles\n",
    "    T=4   # Number of low-level cycles per high-level cycle\n",
    ")\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    learning_rate=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=20,\n",
    "    embeddings_lr=0.001,\n",
    "    weight_decay=1e-4  # Much smaller weight decay\n",
    ")\n",
    "\n",
    "model = HierarchicalReasoningModel(config=hrm_config, device=device)\n",
    "\n",
    "trainer = HRMTrainer(model, config=model_config, device=device)\n",
    "\n",
    "train_dataset = sudoku.SudokuDataset(puzzles, solutions)\n",
    "val_dataset = sudoku.SudokuDataset(test_puzzles, test_solutions)\n",
    "\n",
    "trainer.train(train_dataset, val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39112ab5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acd7994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tensor shape: torch.Size([1, 81])\n",
      "Test tensor unsqueezed: torch.Size([1, 81, 1])\n",
      "HRM import successful\n",
      "Config created: input_dim=1, output_dim=10\n",
      "Model created successfully\n",
      "Test input shape: torch.Size([1, 81])\n",
      "Model output shape: torch.Size([1, 81, 10])\n",
      "Expected shape: (1, 81, 10)\n"
     ]
    }
   ],
   "source": [
    "# Minimal test\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Test basic tensor operation\n",
    "test_tensor = torch.zeros(1, 81)\n",
    "print(f\"Test tensor shape: {test_tensor.shape}\")\n",
    "print(f\"Test tensor unsqueezed: {test_tensor.unsqueeze(-1).shape}\")\n",
    "\n",
    "# Import the HRM module and check for issues\n",
    "try:\n",
    "    from hrm import HRMConfig, HierarchicalReasoningModel\n",
    "    print(\"HRM import successful\")\n",
    "    \n",
    "    # Create config - match the main training config\n",
    "    config = HRMConfig(\n",
    "        input_dim=1,      # Feature dimension per cell\n",
    "        output_dim=10,    # Number of classes (0-9)\n",
    "        hidden_dim=128,   # Hidden dimension\n",
    "        N=2, T=4          # Hierarchical parameters\n",
    "    )\n",
    "    print(f\"Config created: input_dim={config.input_dim}, output_dim={config.output_dim}\")\n",
    "    \n",
    "    # Create model\n",
    "    device = torch.device('cpu')  # Use CPU for simplicity\n",
    "    model = HierarchicalReasoningModel(config=config, device=device)\n",
    "    print(\"Model created successfully\")\n",
    "    \n",
    "    # Test model forward with 2D input (will be converted to 3D internally)\n",
    "    test_input = torch.zeros(1, 81, dtype=torch.float32)\n",
    "    print(f\"Test input shape: {test_input.shape}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(test_input)\n",
    "        print(f\"Model output shape: {output.shape}\")\n",
    "        print(f\"Expected shape: (1, 81, 10)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb67b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Puzzle:\n",
      "[0, 0, 0, 0, 0, 0, 9, 0, 0]\n",
      "[0, 0, 1, 0, 9, 0, 0, 0, 2]\n",
      "[0, 0, 6, 8, 5, 0, 0, 0, 7]\n",
      "[2, 8, 9, 3, 0, 6, 0, 0, 0]\n",
      "[0, 1, 3, 0, 0, 0, 0, 0, 8]\n",
      "[0, 0, 0, 1, 0, 9, 0, 0, 0]\n",
      "[0, 0, 4, 7, 0, 8, 0, 0, 9]\n",
      "[0, 0, 0, 5, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 4, 0, 0, 0]\n",
      "Predicted Solution:\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(6), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(0), np.int64(2)]\n",
      "[np.int64(0), np.int64(0), np.int64(3), np.int64(3), np.int64(3), np.int64(0), np.int64(0), np.int64(0), np.int64(3)]\n",
      "[np.int64(2), np.int64(3), np.int64(3), np.int64(2), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(6), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(2), np.int64(3), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(3)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(2), np.int64(0), np.int64(0), np.int64(0)]\n",
      "True Solution:\n",
      "[np.int64(8), np.int64(4), np.int64(7), np.int64(6), np.int64(3), np.int64(2), np.int64(9), np.int64(1), np.int64(5)]\n",
      "[np.int64(3), np.int64(5), np.int64(1), np.int64(4), np.int64(9), np.int64(7), np.int64(8), np.int64(6), np.int64(2)]\n",
      "[np.int64(9), np.int64(2), np.int64(6), np.int64(8), np.int64(5), np.int64(1), np.int64(3), np.int64(4), np.int64(7)]\n",
      "[np.int64(2), np.int64(8), np.int64(9), np.int64(3), np.int64(4), np.int64(6), np.int64(7), np.int64(5), np.int64(1)]\n",
      "[np.int64(4), np.int64(1), np.int64(3), np.int64(2), np.int64(7), np.int64(5), np.int64(6), np.int64(9), np.int64(8)]\n",
      "[np.int64(7), np.int64(6), np.int64(5), np.int64(1), np.int64(8), np.int64(9), np.int64(2), np.int64(3), np.int64(4)]\n",
      "[np.int64(5), np.int64(3), np.int64(4), np.int64(7), np.int64(6), np.int64(8), np.int64(1), np.int64(2), np.int64(9)]\n",
      "[np.int64(1), np.int64(9), np.int64(8), np.int64(5), np.int64(2), np.int64(3), np.int64(4), np.int64(7), np.int64(6)]\n",
      "[np.int64(6), np.int64(7), np.int64(2), np.int64(9), np.int64(1), np.int64(4), np.int64(5), np.int64(8), np.int64(3)]\n",
      "Cell Accuracy: 0.0247\n",
      "Valid Sudoku: False\n",
      "\n",
      "Sample 2:\n",
      "Puzzle:\n",
      "[0, 0, 0, 0, 0, 7, 8, 0, 3]\n",
      "[0, 0, 6, 5, 0, 0, 0, 0, 1]\n",
      "[8, 0, 0, 3, 0, 0, 9, 5, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 9, 0]\n",
      "[0, 0, 0, 2, 9, 0, 0, 1, 7]\n",
      "[2, 7, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 8, 0, 0, 4, 0, 0]\n",
      "[9, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 9, 4, 3, 0, 0, 0]\n",
      "Predicted Solution:\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(3), np.int64(0), np.int64(2)]\n",
      "[np.int64(0), np.int64(0), np.int64(3), np.int64(3), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6)]\n",
      "[np.int64(3), np.int64(0), np.int64(0), np.int64(2), np.int64(0), np.int64(0), np.int64(3), np.int64(3), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(2), np.int64(3), np.int64(0), np.int64(0), np.int64(6), np.int64(3)]\n",
      "[np.int64(2), np.int64(3), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(2), np.int64(0), np.int64(0)]\n",
      "[np.int64(3), np.int64(0), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(2), np.int64(2), np.int64(0), np.int64(0), np.int64(0)]\n",
      "True Solution:\n",
      "[np.int64(5), np.int64(9), np.int64(1), np.int64(4), np.int64(6), np.int64(7), np.int64(8), np.int64(2), np.int64(3)]\n",
      "[np.int64(3), np.int64(2), np.int64(6), np.int64(5), np.int64(8), np.int64(9), np.int64(7), np.int64(4), np.int64(1)]\n",
      "[np.int64(8), np.int64(4), np.int64(7), np.int64(3), np.int64(1), np.int64(2), np.int64(9), np.int64(5), np.int64(6)]\n",
      "[np.int64(6), np.int64(1), np.int64(8), np.int64(7), np.int64(5), np.int64(4), np.int64(3), np.int64(9), np.int64(2)]\n",
      "[np.int64(4), np.int64(5), np.int64(3), np.int64(2), np.int64(9), np.int64(8), np.int64(6), np.int64(1), np.int64(7)]\n",
      "[np.int64(2), np.int64(7), np.int64(9), np.int64(6), np.int64(3), np.int64(1), np.int64(5), np.int64(8), np.int64(4)]\n",
      "[np.int64(1), np.int64(3), np.int64(5), np.int64(8), np.int64(2), np.int64(6), np.int64(4), np.int64(7), np.int64(9)]\n",
      "[np.int64(9), np.int64(6), np.int64(4), np.int64(1), np.int64(7), np.int64(5), np.int64(2), np.int64(3), np.int64(8)]\n",
      "[np.int64(7), np.int64(8), np.int64(2), np.int64(9), np.int64(4), np.int64(3), np.int64(1), np.int64(6), np.int64(5)]\n",
      "Cell Accuracy: 0.0247\n",
      "Valid Sudoku: False\n",
      "\n",
      "Sample 3:\n",
      "Puzzle:\n",
      "[0, 3, 2, 0, 0, 9, 0, 0, 4]\n",
      "[9, 0, 0, 0, 0, 2, 3, 0, 0]\n",
      "[0, 4, 0, 0, 0, 0, 9, 0, 5]\n",
      "[8, 0, 0, 1, 3, 0, 0, 0, 0]\n",
      "[0, 5, 0, 0, 4, 0, 0, 7, 0]\n",
      "[0, 0, 0, 9, 5, 0, 4, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 7, 9, 0, 0, 6, 0]\n",
      "[0, 0, 0, 3, 0, 0, 0, 0, 9]\n",
      "Predicted Solution:\n",
      "[np.int64(0), np.int64(2), np.int64(2), np.int64(0), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(2)]\n",
      "[np.int64(3), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(2), np.int64(2), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(0), np.int64(3)]\n",
      "[np.int64(3), np.int64(0), np.int64(0), np.int64(6), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(2), np.int64(0), np.int64(0), np.int64(3), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(3), np.int64(0), np.int64(2), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
      "[np.int64(0), np.int64(6), np.int64(0), np.int64(3), np.int64(3), np.int64(0), np.int64(0), np.int64(3), np.int64(0)]\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3)]\n",
      "True Solution:\n",
      "[np.int64(7), np.int64(3), np.int64(2), np.int64(5), np.int64(1), np.int64(9), np.int64(6), np.int64(8), np.int64(4)]\n",
      "[np.int64(9), np.int64(8), np.int64(5), np.int64(4), np.int64(6), np.int64(2), np.int64(3), np.int64(1), np.int64(7)]\n",
      "[np.int64(6), np.int64(4), np.int64(1), np.int64(8), np.int64(7), np.int64(3), np.int64(9), np.int64(2), np.int64(5)]\n",
      "[np.int64(8), np.int64(2), np.int64(4), np.int64(1), np.int64(3), np.int64(7), np.int64(5), np.int64(9), np.int64(6)]\n",
      "[np.int64(3), np.int64(5), np.int64(9), np.int64(2), np.int64(4), np.int64(6), np.int64(8), np.int64(7), np.int64(1)]\n",
      "[np.int64(1), np.int64(6), np.int64(7), np.int64(9), np.int64(5), np.int64(8), np.int64(4), np.int64(3), np.int64(2)]\n",
      "[np.int64(4), np.int64(9), np.int64(8), np.int64(6), np.int64(2), np.int64(1), np.int64(7), np.int64(5), np.int64(3)]\n",
      "[np.int64(5), np.int64(1), np.int64(3), np.int64(7), np.int64(9), np.int64(4), np.int64(2), np.int64(6), np.int64(8)]\n",
      "[np.int64(2), np.int64(7), np.int64(6), np.int64(3), np.int64(8), np.int64(5), np.int64(1), np.int64(4), np.int64(9)]\n",
      "Cell Accuracy: 0.0247\n",
      "Valid Sudoku: False\n",
      "\n",
      "=== Sudoku Validation Results ===\n",
      "Total samples validated: 10\n",
      "Valid Sudoku solutions: 0\n",
      "Sudoku validity rate: 0.0000 (0.00%)\n",
      "Average cell accuracy: 0.0296 (2.96%)\n",
      "\n",
      "=== Sudoku Validation Results ===\n",
      "Total samples validated: 10\n",
      "Valid Sudoku solutions: 0\n",
      "Sudoku validity rate: 0.0000 (0.00%)\n",
      "Average cell accuracy: 0.0296 (2.96%)\n"
     ]
    }
   ],
   "source": [
    "def validate_sudoku_predictions(model, dataset, num_samples=10):\n",
    "    \"\"\"\n",
    "    Validate that the model's predictions form valid Sudoku solutions.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained HRM model\n",
    "        dataset: SudokuDataset to validate on\n",
    "        num_samples: Number of samples to validate\n",
    "    \n",
    "    Returns:\n",
    "        dict: Validation results including accuracy metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    def is_valid_sudoku(grid):\n",
    "        \"\"\"Check if a 9x9 sudoku grid is valid\"\"\"\n",
    "        # Check rows\n",
    "        for row in grid:\n",
    "            if len(set(row)) != 9 or not all(1 <= x <= 9 for x in row):\n",
    "                return False\n",
    "        \n",
    "        # Check columns\n",
    "        for col in range(9):\n",
    "            column = [grid[row][col] for row in range(9)]\n",
    "            if len(set(column)) != 9:\n",
    "                return False\n",
    "        \n",
    "        # Check 3x3 boxes\n",
    "        for box_row in range(3):\n",
    "            for box_col in range(3):\n",
    "                box = []\n",
    "                for r in range(3):\n",
    "                    for c in range(3):\n",
    "                        box.append(grid[box_row*3 + r][box_col*3 + c])\n",
    "                if len(set(box)) != 9:\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def calculate_cell_accuracy(predicted, target):\n",
    "        \"\"\"Calculate per-cell accuracy\"\"\"\n",
    "        return (predicted == target).float().mean().item()\n",
    "    \n",
    "    # Sample validation data\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    results = {\n",
    "        'valid_sudokus': 0,\n",
    "        'total_samples': 0,\n",
    "        'cell_accuracies': [],\n",
    "        'sudoku_validity_rate': 0.0,\n",
    "        'average_cell_accuracy': 0.0\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            puzzle, solution = batch[\"puzzle\"], batch[\"solution\"]\n",
    "            puzzle = puzzle.to(device).float()\n",
    "            solution = solution.to(device).long()\n",
    "            \n",
    "            # Get model prediction\n",
    "            if puzzle.dim() == 2:\n",
    "                puzzle = puzzle.unsqueeze(-1)  # Add feature dimension\n",
    "            \n",
    "            output = model(puzzle)  # Shape: (1, 81, 10)\n",
    "            predicted = output.argmax(dim=-1)  # Shape: (1, 81)\n",
    "            \n",
    "            # Convert to numpy and reshape to 9x9\n",
    "            pred_grid = predicted.cpu().numpy()[0].reshape(9, 9)\n",
    "            true_grid = solution.cpu().numpy()[0].reshape(9, 9)\n",
    "            \n",
    "            # Calculate cell accuracy\n",
    "            cell_acc = calculate_cell_accuracy(predicted[0], solution[0])\n",
    "            results['cell_accuracies'].append(cell_acc)\n",
    "            \n",
    "            # Check if prediction is valid sudoku\n",
    "            is_valid = is_valid_sudoku(pred_grid)\n",
    "            if is_valid:\n",
    "                results['valid_sudokus'] += 1\n",
    "            \n",
    "            results['total_samples'] += 1\n",
    "            \n",
    "            # Print first few examples\n",
    "            if i < 3:\n",
    "                print(f\"\\nSample {i+1}:\")\n",
    "                print(\"Puzzle:\")\n",
    "                puzzle_display = puzzle.cpu().numpy()[0].reshape(9, 9)\n",
    "                for row in puzzle_display:\n",
    "                    print([int(x) for x in row])\n",
    "                \n",
    "                print(\"Predicted Solution:\")\n",
    "                for row in pred_grid:\n",
    "                    print(list(row))\n",
    "                \n",
    "                print(\"True Solution:\")\n",
    "                for row in true_grid:\n",
    "                    print(list(row))\n",
    "                \n",
    "                print(f\"Cell Accuracy: {cell_acc:.4f}\")\n",
    "                print(f\"Valid Sudoku: {is_valid}\")\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    results['sudoku_validity_rate'] = results['valid_sudokus'] / results['total_samples']\n",
    "    results['average_cell_accuracy'] = sum(results['cell_accuracies']) / len(results['cell_accuracies'])\n",
    "    \n",
    "    print(f\"\\n=== Sudoku Validation Results ===\")\n",
    "    print(f\"Total samples validated: {results['total_samples']}\")\n",
    "    print(f\"Valid Sudoku solutions: {results['valid_sudokus']}\")\n",
    "    print(f\"Sudoku validity rate: {results['sudoku_validity_rate']:.4f} ({results['sudoku_validity_rate']*100:.2f}%)\")\n",
    "    print(f\"Average cell accuracy: {results['average_cell_accuracy']:.4f} ({results['average_cell_accuracy']*100:.2f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run validation\n",
    "validation_results = validate_sudoku_predictions(model, val_dataset, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed2d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
