{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd58118",
   "metadata": {},
   "source": [
    "HRM Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62315096",
   "metadata": {},
   "source": [
    "load sudoku data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88af0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 81)\n",
      "(1000, 81)\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ _ _ 4 _ 9 _ 5    0| 7 3 2 8 4 6 9 1 5\n",
      "1| _ 8 _ _ _ 1 2 _ _    1| 4 8 9 5 3 1 2 7 6\n",
      "2| 5 _ _ 2 _ _ 3 4 _    2| 5 1 6 2 7 9 3 4 8\n",
      "3| _ 7 8 4 _ _ _ 2 _    3| 1 7 8 4 6 3 5 2 9\n",
      "4| _ _ _ _ _ _ _ _ _    4| 9 5 4 1 8 2 6 3 7\n",
      "5| 6 _ _ _ _ _ 4 8 1    5| 6 2 3 9 5 7 4 8 1\n",
      "6| _ _ _ 7 _ _ 8 _ _    6| 3 9 5 7 1 4 8 6 2\n",
      "7| _ 6 _ _ _ _ 7 _ _    7| 8 6 1 3 2 5 7 9 4\n",
      "8| _ _ _ 6 9 8 _ _ _    8| 2 4 7 6 9 8 1 5 3\n",
      "\n",
      "Statistics: 25 filled, 56 blank cells\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import pydantic \n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from dataset.sudoku import SudokuDataset\n",
    "\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "import dataset.sudoku as sudoku\n",
    "\n",
    "def load_sudoku_data(data_path: str, max_samples: int = 1000):\n",
    "    # Load the dictionary that was saved\n",
    "    data = np.load(data_path, allow_pickle=True).item()\n",
    " \n",
    "    puzzles = []\n",
    "    solutions = []\n",
    "\n",
    "    # Extract puzzles and solutions from the dictionary\n",
    "    for i in range(min(max_samples, len(data))):\n",
    "        if i in data:\n",
    "            puzzles.append(data[i][\"puzzle\"])\n",
    "            solutions.append(data[i][\"solution\"])\n",
    "\n",
    "    return np.array(puzzles), np.array(solutions)\n",
    "\n",
    "# presenting the data\n",
    "puzzles, solutions = load_sudoku_data(\"./data/sudoku_train.npy\")\n",
    "test_puzzles, test_solutions = load_sudoku_data(\"./data/sudoku_test.npy\")\n",
    "\n",
    "print(test_puzzles.shape)\n",
    "print(test_solutions.shape)\n",
    "\n",
    "sudoku.display_puzzle_pair(puzzles[0].reshape(9, 9), solutions[0].reshape(9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e0b14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RecurrentModule(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim: int, \n",
    "        hidden_dim: int = 128,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # going with lstm to simplify understanding \n",
    "        self.layers = nn.ModuleList(\n",
    "            nn.LSTM(input_size=input_dim, hidden_size=input_dim,\n",
    "                   num_layers=num_layers, batch_first=True, dropout=dropout) for _ in range(num_layers)\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Linear(input_dim, input_dim, bias=False)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "\n",
    "    def forward(self, x, hidden=None) -> torch.Tensor:\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Initialize hidden state if not provided\n",
    "        if hidden is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=x.device)\n",
    "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=x.device)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x, hidden = layer(x, hidden)\n",
    "\n",
    "        # should add attention?\n",
    "\n",
    "        output = self.layer_norm(x)\n",
    "\n",
    "        output = self.projection(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HierarchicalReasoningModel\n",
    " # added to ensure HRMConfig is defined successfully\n",
    "class HRMConfig(pydantic.BaseModel):\n",
    "    input_dim: int = 64\n",
    "    hidden_dim: int = 128\n",
    "    num_layers: int = 4\n",
    "    dropout: float = 0.1\n",
    "    output_dim: int = 10\n",
    "\n",
    "    N: int = 2  # number of high-level module cycles\n",
    "    T: int = 4  # number of low-level module cycles\n",
    "    max_seq_len: int = 256\n",
    "\n",
    "class ModelConfig(pydantic.BaseModel):\n",
    "    learning_rate: float = 0.001\n",
    "    batch_size: int = 32\n",
    "    max_epochs: int = 200\n",
    "    embeddings_lr: float = 0.001\n",
    "    weight_decay: float = 1.0\n",
    "\n",
    "class HierarchicalReasoningModel(nn.Module):\n",
    "    def __init__(self, config: HRMConfig, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.total_steps = config.N * config.T  # total steps in the HRM\n",
    "        self.device = device\n",
    "        self.N = config.N\n",
    "        self.T = config.T\n",
    "        # Define model layers here\n",
    "\n",
    "        # Input projection (project puzzle embedding dim -> hidden)\n",
    "        self.input_proj = nn.Linear(config.input_dim, config.hidden_dim)\n",
    "\n",
    "        self.High_net = RecurrentModule(\n",
    "            input_dim=self.config.input_dim,\n",
    "            num_layers=self.config.num_layers,\n",
    "            hidden_dim=self.config.hidden_dim,\n",
    "            dropout=self.config.dropout\n",
    "        )\n",
    "\n",
    "        self.Low_net = RecurrentModule(\n",
    "            input_dim=self.config.input_dim,\n",
    "            num_layers=self.config.num_layers,\n",
    "            hidden_dim=self.config.hidden_dim,\n",
    "            dropout=self.config.dropout\n",
    "        )\n",
    "\n",
    "        # Combine and project to latent (hrm latent == output_dim)\n",
    "        self.layer_norm = nn.LayerNorm(self.config.hidden_dim * 2)  # added\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_dim * 2, self.config.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.config.dropout),\n",
    "            nn.Linear(self.config.hidden_dim, self.config.hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.config.dropout),\n",
    "            nn.Linear(self.config.hidden_dim // 2, self.config.output_dim)\n",
    "        )\n",
    "\n",
    "        # Projections\n",
    "        self.low_level_proj = nn.Linear(self.config.hidden_dim, self.config.hidden_dim, bias=False)\n",
    "        self.high_level_proj = nn.Linear(self.config.hidden_dim, self.config.hidden_dim, bias=False)\n",
    "\n",
    "    def initialize_hidden_states(self, batch_size: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Initialize hidden states for low and high level modules\n",
    "        z0_L = torch.zeros(batch_size, 1,  self.config.hidden_dim, device=self.device)\n",
    "        z0_H = torch.zeros(batch_size, 1, self.config.hidden_dim, device=self.device)\n",
    "        return z0_H, z0_L\n",
    "\n",
    "\n",
    "    def level_step(self,\n",
    "                   first_level: torch.Tensor,\n",
    "                   second_level: torch.Tensor,\n",
    "                   input_embedding: torch.Tensor,\n",
    "                   network: nn.Module,\n",
    "                   projection: nn.Module\n",
    "                   ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        level_influence = projection(second_level)\n",
    "        combined = first_level + level_influence + input_embedding\n",
    "        for layer in network.layers:\n",
    "            combined, _ = layer(combined)\n",
    "        return combined\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden_states=None):\n",
    "        # x: (B, 81, input_dim)\n",
    "        x = self.input_proj(x)\n",
    "        # Initialize hidden states if not provided\n",
    "        if hidden_states is None:\n",
    "            high_level_state, low_level_state = self.initialize_hidden_states(x.shape[0])\n",
    "        else:\n",
    "            high_level_state, low_level_state = hidden_states\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for step in range(self.total_steps - 1):\n",
    "                low_level_state = self.level_step(\n",
    "                    low_level_state, high_level_state, x, self.Low_net, self.low_level_proj\n",
    "                )\n",
    "\n",
    "                if(step + 1) % self.T == 0:\n",
    "                    high_level_state = self.level_step(\n",
    "                        high_level_state, low_level_state, x, self.High_net, self.high_level_proj\n",
    "                    )\n",
    "\n",
    "        # 1 step with gradient\n",
    "        low_level_state = self.level_step(\n",
    "            low_level_state, high_level_state, x, self.Low_net, self.low_level_proj\n",
    "        )\n",
    "        high_level_state = self.level_step(\n",
    "            high_level_state, low_level_state, x, self.High_net, self.high_level_proj\n",
    "        )\n",
    "\n",
    "        combined = torch.cat([low_level_state, high_level_state], dim=-1)\n",
    "        combined = self.layer_norm(combined)\n",
    "\n",
    "        latent = self.output_proj(combined)  # (B, 81, output_dim)\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a1aef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelConfig(pydantic.BaseModel):\n",
    "    learning_rate: float = 0.001\n",
    "    batch_size: int = 32\n",
    "    max_epochs: int = 200\n",
    "    embeddings_lr: float = 0.001\n",
    "    weight_decay: float = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d02fe839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class HRMTrainer:\n",
    "    \"\"\"\n",
    "    Trainer class for the Hierarchical Reasoning Model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: HierarchicalReasoningModel, \n",
    "                 adapter: sudoku.SudokuAdapter, \n",
    "                 config=None, device=None):\n",
    "        \n",
    "        self.model = model\n",
    "        self.adapter = adapter\n",
    "        self.config = config or ModelConfig()\n",
    "        self.device = device or torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.adapter.to(self.device)\n",
    "        \n",
    "        # Training components\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.model.parameters()) + list(self.adapter.parameters()),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        \n",
    "        # Training state\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model_state = None\n",
    "        self.epochs_without_improvement = 0\n",
    "        \n",
    "        # Early stopping params\n",
    "        self.patience = 15\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    def _accuracy(self, logits: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "        # logits: (B, 81, C) targets: (B,81)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        correct = (preds == targets).float().sum().item()\n",
    "        total = targets.numel()\n",
    "        return correct / total\n",
    "\n",
    "    def _run_epoch(self, loader: DataLoader, train: bool = True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "            self.adapter.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            self.adapter.eval()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        total_batches = 0\n",
    "        for batch in loader:\n",
    "            puzzles, solutions = batch[\"puzzle\"], batch[\"solution\"]  # expecting dataset returns (input, target)\n",
    "            puzzles = puzzles.to(self.device)  # (B,81)\n",
    "            solutions = solutions.to(self.device)  # (B,81)\n",
    "\n",
    "            if train:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            puzzle_embeds = self.adapter.encode_puzzle(puzzles)\n",
    "            # Model forward -> latent (B,81,output_dim)\n",
    "            # Insert before latent = self.model(puzzle_embeds)\n",
    "            latent = self.model(puzzle_embeds)\n",
    "            # Decode to logits (B,81,10)\n",
    "            logits = self.adapter.decoder(latent)\n",
    "\n",
    "            loss = self.criterion(logits.view(-1, logits.size(-1)), solutions.view(-1))\n",
    "            acc = self._accuracy(logits, solutions)\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                torch.nn.utils.clip_grad_norm_(self.adapter.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            total_batches += 1\n",
    "        return epoch_loss / max(1, total_batches), epoch_acc / max(1, total_batches)\n",
    "\n",
    "    def train(self, train_dataset, val_dataset=None):\n",
    "        epochs = self.config.max_epochs\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size) if val_dataset is not None else None\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = self._run_epoch(train_loader, train=True)\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accuracies.append(train_acc)\n",
    "\n",
    "            if val_loader is not None:\n",
    "                with torch.no_grad():\n",
    "                    val_loss, val_acc = self._run_epoch(val_loader, train=False)\n",
    "                self.val_losses.append(val_loss)\n",
    "                self.val_accuracies.append(val_acc)\n",
    "                self.scheduler.step(val_loss)\n",
    "            else:\n",
    "                val_loss, val_acc = train_loss, train_acc  # fallback\n",
    "\n",
    "            improved = val_loss < self.best_val_loss - 1e-5\n",
    "            if improved:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_state = {\n",
    "                    'model': self.model.state_dict(),\n",
    "                    'adapter': self.adapter.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'val_loss': val_loss\n",
    "                }\n",
    "                self.epochs_without_improvement = 0\n",
    "            else:\n",
    "                self.epochs_without_improvement += 1\n",
    "\n",
    "            print(f\"Epoch {epoch:03d} | Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f} | LR {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            if self.epochs_without_improvement >= self.patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        # Save best checkpoint\n",
    "        if self.best_model_state is not None:\n",
    "            torch.save(self.best_model_state, 'results/best_model.pt')\n",
    "            print(f\"Best model (val_loss={self.best_model_state['val_loss']:.4f}) saved to results/best_model.pt\")\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        loader = DataLoader(dataset, batch_size=self.config.batch_size)\n",
    "        with torch.no_grad():\n",
    "            loss, acc = self._run_epoch(loader, train=False)\n",
    "        print(f\"Eval Loss {loss:.4f} Acc {acc:.4f}\")\n",
    "        return loss, acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7884a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorhugogermano/Development/hrm/dataset/sudoku.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'puzzle': torch.tensor(self.puzzles[idx], dtype=torch.long),\n",
      "/Users/victorhugogermano/Development/hrm/dataset/sudoku.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'solution': torch.tensor(self.solutions[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss 2.7467 Acc 0.0963 | Val Loss 2.4840 Acc 0.1126 | LR 1.00e-03\n",
      "Epoch 002 | Train Loss 2.5664 Acc 0.1144 | Val Loss 2.3825 Acc 0.1115 | LR 1.00e-03\n",
      "Epoch 003 | Train Loss 2.4543 Acc 0.1090 | Val Loss 2.2974 Acc 0.1119 | LR 1.00e-03\n",
      "Epoch 004 | Train Loss 2.3390 Acc 0.1223 | Val Loss 2.2459 Acc 0.1107 | LR 1.00e-03\n",
      "Epoch 005 | Train Loss 2.3130 Acc 0.1119 | Val Loss 2.2224 Acc 0.1114 | LR 1.00e-03\n",
      "Epoch 006 | Train Loss 2.2689 Acc 0.1142 | Val Loss 2.2117 Acc 0.1115 | LR 1.00e-03\n",
      "Epoch 007 | Train Loss 2.2524 Acc 0.1169 | Val Loss 2.2121 Acc 0.1118 | LR 1.00e-03\n",
      "Epoch 008 | Train Loss 2.2368 Acc 0.1026 | Val Loss 2.2097 Acc 0.1103 | LR 1.00e-03\n",
      "Epoch 009 | Train Loss 2.2190 Acc 0.1236 | Val Loss 2.2063 Acc 0.1114 | LR 1.00e-03\n",
      "Epoch 010 | Train Loss 2.2159 Acc 0.1130 | Val Loss 2.2061 Acc 0.1113 | LR 1.00e-03\n",
      "Best model (val_loss=2.2061) saved to results/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "config = HRMConfig(\n",
    "    input_dim=512,\n",
    "    output_dim=512,\n",
    "    hidden_dim=512,\n",
    "    num_layers=4,\n",
    "    dropout=0.1,\n",
    "    \n",
    ")\n",
    "\n",
    "model = HierarchicalReasoningModel(config=config, device=device)\n",
    "\n",
    "adapter = sudoku.SudokuAdapter(hidden_dim=256, hrm_input_dim=512, hrm_output_dim=512)\n",
    "\n",
    "trainer = HRMTrainer(model, adapter, config=ModelConfig(max_epochs=10 ),  device=device)\n",
    "\n",
    "train_dataset = sudoku.SudokuDataset(puzzles, solutions)\n",
    "val_dataset = sudoku.SudokuDataset(test_puzzles, test_solutions)\n",
    "\n",
    "\n",
    "trainer.train(train_dataset, val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39112ab5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe78d6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "tensor([[4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        ...,\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6],\n",
      "        [4, 6, 6,  ..., 6, 6, 6]], device='mps:0')\n",
      "Cell Accuracy: 0.1108\n",
      "Given Cell Accuracy: 0.1084\n",
      "Puzzle Solved Rate: 0.0000\n",
      "Validity Rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.sudoku import SudokuDataset, SudokuAdapter  # adjust if path differs\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "# --- 1. Rebuild config / model / adapter exactly as during training ---\n",
    "hrm_config = HRMConfig(\n",
    "    input_dim=512,\n",
    "    output_dim=512,\n",
    "    hidden_dim=512,\n",
    "    num_layers=4,\n",
    "    dropout=0.1,\n",
    ")\n",
    "model = HierarchicalReasoningModel(config=hrm_config, device=device)\n",
    "adapter = SudokuAdapter(hidden_dim=256, hrm_input_dim=512, hrm_output_dim=512)\n",
    "\n",
    "ckpt = torch.load('results/best_model.pt', map_location=device)\n",
    "model.load_state_dict(ckpt['model'])\n",
    "adapter.load_state_dict(ckpt['adapter'])\n",
    "model.to(device).eval()\n",
    "adapter.to(device).eval()\n",
    "\n",
    "# --- 2. Prepare test dataset (reuse already loaded arrays or reload) ---\n",
    "test_puzzles, test_solutions = load_sudoku_data(\"./data/sudoku_test.npy\")\n",
    "test_ds = SudokuDataset(test_puzzles, test_solutions)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "# --- 3. Metrics helpers ---\n",
    "def is_valid_sudoku(grid9):\n",
    "    # grid9: (9,9) ints 1-9\n",
    "    rows = all(set(r) == set(range(1,10)) for r in grid9)\n",
    "    cols = all(set(grid9[:,c]) == set(range(1,10)) for c in range(9))\n",
    "    boxes = True\n",
    "    for br in range(0,9,3):\n",
    "        for bc in range(0,9,3):\n",
    "            box = grid9[br:br+3, bc:bc+3].reshape(-1)\n",
    "            if set(box) != set(range(1,10)):\n",
    "                boxes = False\n",
    "                break\n",
    "    return rows and cols and boxes\n",
    "\n",
    "total_cells = 0\n",
    "correct_cells = 0\n",
    "correct_given = 0\n",
    "total_given = 0\n",
    "solved_puzzles = 0\n",
    "valid_puzzles = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        puzzles = batch['puzzle'].to(device)    # (B,81) 0 means empty?\n",
    "        solutions = batch['solution'].to(device)  # (B,81) digits 1..9\n",
    "        embeds = adapter.encode_puzzle(puzzles)\n",
    "        latent = model(embeds)\n",
    "        logits = adapter.decoder(latent)  # (B,81,10) if classes 0-9\n",
    "        preds = logits.argmax(-1)  # predicted digits (0-9)\n",
    "        print(preds)\n",
    "        # If class 0 represents empty, map 0->0 else digits already aligned; adjust if needed:\n",
    "        # Assume adapter used 0..9 with 0 as blank -> convert blanks to solution guesses?\n",
    "        # If during training target had digits 0..9 (with 0 for blank) adjust here.\n",
    "        # If targets are 1..9 only (no 0), ensure preds==0 replaced by a guess:\n",
    "        mask_blank_target = (solutions == 0)\n",
    "        # Usually solutions should have 1..9; skip if not.\n",
    "\n",
    "        correct = (preds == solutions)\n",
    "        total_cells += solutions.numel()\n",
    "        correct_cells += correct.sum().item()\n",
    "\n",
    "        # Given mask (original puzzle non-zero)\n",
    "        given_mask = (puzzles > 0)\n",
    "        correct_given += (correct & given_mask).sum().item()\n",
    "        total_given += given_mask.sum().item()\n",
    "\n",
    "        # Whole puzzle solved?\n",
    "        solved_puzzles += (correct.view(puzzles.size(0), -1).all(dim=1).sum().item())\n",
    "\n",
    "        # Validity check on predicted full grid (fill blanks with preds)\n",
    "        pred_full = preds.view(-1,9,9).cpu().numpy()\n",
    "        for g in pred_full:\n",
    "            if (g > 0).all() and is_valid_sudoku(g):\n",
    "                valid_puzzles += 1\n",
    "\n",
    "cell_acc = correct_cells / total_cells\n",
    "given_acc = correct_given / max(1,total_given)\n",
    "puzzle_acc = solved_puzzles / len(test_ds)\n",
    "valid_rate = valid_puzzles / len(test_ds)\n",
    "\n",
    "print(f\"Cell Accuracy: {cell_acc:.4f}\")\n",
    "print(f\"Given Cell Accuracy: {given_acc:.4f}\")\n",
    "print(f\"Puzzle Solved Rate: {puzzle_acc:.4f}\")\n",
    "print(f\"Validity Rate: {valid_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd7994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
