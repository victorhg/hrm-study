{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd58118",
   "metadata": {},
   "source": [
    "HRM Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62315096",
   "metadata": {},
   "source": [
    "load sudoku data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88af0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 81)\n",
      "(400, 81)\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| 7 5 2 _ 4 _ _ 3 9    0| 7 5 2 6 4 8 1 3 9\n",
      "1| 8 _ 3 1 _ _ 2 4 7    1| 8 6 3 1 5 9 2 4 7\n",
      "2| 1 4 9 2 7 3 _ _ 5    2| 1 4 9 2 7 3 6 8 5\n",
      "3| _ _ 5 9 8 _ _ 1 _    3| 3 2 5 9 8 4 7 1 6\n",
      "4| 6 _ _ _ _ 7 _ 9 _    4| 6 8 1 5 2 7 3 9 4\n",
      "5| 9 7 4 3 6 _ 5 _ 8    5| 9 7 4 3 6 1 5 2 8\n",
      "6| _ _ 8 7 1 2 _ 6 3    6| 5 9 8 7 1 2 4 6 3\n",
      "7| 4 _ 6 8 3 _ _ 7 2    7| 4 1 6 8 3 5 9 7 2\n",
      "8| _ 3 7 4 _ _ _ 5 _    8| 2 3 7 4 9 6 8 5 1\n",
      "\n",
      "Statistics: 49 filled, 32 blank cells\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import pydantic \n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from dataset.sudoku import SudokuDataset\n",
    "\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "import dataset.sudoku as sudoku\n",
    "\n",
    "def load_sudoku_data(data_path: str, max_samples: int = 2000):\n",
    "    # Load the dictionary that was saved\n",
    "    data = np.load(data_path, allow_pickle=True).item()\n",
    " \n",
    "    puzzles = []\n",
    "    solutions = []\n",
    "\n",
    "    # Extract puzzles and solutions from the dictionary\n",
    "    for i in range(min(max_samples, len(data))):\n",
    "        if i in data:\n",
    "            puzzles.append(data[i][\"puzzle\"])\n",
    "            solutions.append(data[i][\"solution\"])\n",
    "\n",
    "    return np.array(puzzles), np.array(solutions)\n",
    "\n",
    "# presenting the data\n",
    "puzzles, solutions = load_sudoku_data(\"./data/sudoku_train.npy\")\n",
    "test_puzzles, test_solutions = load_sudoku_data(\"./data/sudoku_test.npy\")\n",
    "\n",
    "print(test_puzzles.shape)\n",
    "print(test_solutions.shape)\n",
    "\n",
    "sudoku.display_puzzle_pair(puzzles[0].reshape(9, 9), solutions[0].reshape(9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7884a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss 2.1338 Acc 0.5266 | Val Loss 2.1338 Acc 0.5266 | LR 1.00e-04\n",
      "Epoch 002 | Train Loss 1.4811 Acc 0.6568 | Val Loss 1.4733 Acc 0.6687 | LR 2.00e-04\n",
      "Epoch 003 | Train Loss 1.4759 Acc 0.6610 | Val Loss 1.4759 Acc 0.6610 | LR 3.00e-04\n",
      "Epoch 004 | Train Loss 1.4724 Acc 0.6670 | Val Loss 1.4689 Acc 0.6733 | LR 4.00e-04\n",
      "Epoch 005 | Train Loss 1.4711 Acc 0.6704 | Val Loss 1.4711 Acc 0.6704 | LR 5.00e-04\n",
      "Epoch 006 | Train Loss 1.4728 Acc 0.6688 | Val Loss 1.4676 Acc 0.6736 | LR 5.00e-04\n",
      "Epoch 007 | Train Loss 1.4681 Acc 0.6718 | Val Loss 1.4681 Acc 0.6718 | LR 5.00e-04\n",
      "Epoch 008 | Train Loss 1.4663 Acc 0.6743 | Val Loss 1.4663 Acc 0.6732 | LR 5.00e-04\n",
      "Epoch 009 | Train Loss 1.4662 Acc 0.6741 | Val Loss 1.4662 Acc 0.6741 | LR 5.00e-04\n",
      "Epoch 010 | Train Loss 1.4653 Acc 0.6741 | Val Loss 1.4645 Acc 0.6758 | LR 5.00e-04\n",
      "Epoch 011 | Train Loss 1.4648 Acc 0.6749 | Val Loss 1.4648 Acc 0.6749 | LR 5.00e-04\n",
      "Epoch 012 | Train Loss 1.4644 Acc 0.6755 | Val Loss 1.4647 Acc 0.6747 | LR 5.00e-04\n",
      "Epoch 013 | Train Loss 1.4637 Acc 0.6758 | Val Loss 1.4637 Acc 0.6758 | LR 5.00e-04\n",
      "Epoch 014 | Train Loss 1.4632 Acc 0.6769 | Val Loss 1.4628 Acc 0.6752 | LR 5.00e-04\n",
      "Epoch 015 | Train Loss 1.4588 Acc 0.6814 | Val Loss 1.4588 Acc 0.6814 | LR 5.00e-04\n",
      "Epoch 016 | Train Loss 1.4512 Acc 0.6864 | Val Loss 1.4389 Acc 0.6947 | LR 5.00e-04\n",
      "Epoch 017 | Train Loss 1.4235 Acc 0.7047 | Val Loss 1.4235 Acc 0.7047 | LR 5.00e-04\n",
      "Epoch 018 | Train Loss 1.3918 Acc 0.7204 | Val Loss 1.3703 Acc 0.7335 | LR 5.00e-04\n",
      "Epoch 019 | Train Loss 1.3623 Acc 0.7376 | Val Loss 1.3623 Acc 0.7376 | LR 5.00e-04\n",
      "Epoch 020 | Train Loss 1.3319 Acc 0.7538 | Val Loss 1.3147 Acc 0.7625 | LR 5.00e-04\n",
      "Epoch 021 | Train Loss 1.3043 Acc 0.7693 | Val Loss 1.3043 Acc 0.7693 | LR 5.00e-04\n",
      "Epoch 022 | Train Loss 1.2748 Acc 0.7875 | Val Loss 1.2450 Acc 0.8040 | LR 5.00e-04\n",
      "Epoch 023 | Train Loss 1.2486 Acc 0.8042 | Val Loss 1.2486 Acc 0.8042 | LR 5.00e-04\n",
      "Epoch 024 | Train Loss 1.2240 Acc 0.8204 | Val Loss 1.1872 Acc 0.8453 | LR 5.00e-04\n",
      "Epoch 025 | Train Loss 1.1981 Acc 0.8393 | Val Loss 1.1981 Acc 0.8393 | LR 5.00e-04\n",
      "Epoch 026 | Train Loss 1.1822 Acc 0.8524 | Val Loss 1.1404 Acc 0.8830 | LR 5.00e-04\n",
      "Epoch 027 | Train Loss 1.1617 Acc 0.8677 | Val Loss 1.1617 Acc 0.8677 | LR 5.00e-04\n",
      "Epoch 028 | Train Loss 1.1518 Acc 0.8746 | Val Loss 1.1168 Acc 0.9013 | LR 5.00e-04\n",
      "Epoch 029 | Train Loss 1.1378 Acc 0.8872 | Val Loss 1.1378 Acc 0.8872 | LR 5.00e-04\n",
      "Epoch 030 | Train Loss 1.1326 Acc 0.8906 | Val Loss 1.0954 Acc 0.9193 | LR 5.00e-04\n",
      "Epoch 031 | Train Loss 1.1270 Acc 0.8946 | Val Loss 1.1270 Acc 0.8946 | LR 5.00e-04\n",
      "Epoch 032 | Train Loss 1.1210 Acc 0.9007 | Val Loss 1.0811 Acc 0.9269 | LR 5.00e-04\n",
      "Epoch 033 | Train Loss 1.1170 Acc 0.9017 | Val Loss 1.1170 Acc 0.9017 | LR 5.00e-04\n",
      "Epoch 034 | Train Loss 1.1111 Acc 0.9072 | Val Loss 1.0762 Acc 0.9341 | LR 5.00e-04\n",
      "Epoch 035 | Train Loss 1.1047 Acc 0.9117 | Val Loss 1.1047 Acc 0.9117 | LR 5.00e-04\n",
      "Epoch 036 | Train Loss 1.1062 Acc 0.9111 | Val Loss 1.0691 Acc 0.9372 | LR 5.00e-04\n",
      "Epoch 037 | Train Loss 1.1026 Acc 0.9135 | Val Loss 1.1026 Acc 0.9135 | LR 5.00e-04\n",
      "Epoch 038 | Train Loss 1.0980 Acc 0.9165 | Val Loss 1.0645 Acc 0.9420 | LR 5.00e-04\n",
      "Epoch 039 | Train Loss 1.0951 Acc 0.9191 | Val Loss 1.0951 Acc 0.9191 | LR 5.00e-04\n",
      "Epoch 040 | Train Loss 1.0927 Acc 0.9201 | Val Loss 1.0542 Acc 0.9470 | LR 5.00e-04\n",
      "Epoch 041 | Train Loss 1.0900 Acc 0.9216 | Val Loss 1.0900 Acc 0.9216 | LR 5.00e-04\n",
      "Epoch 042 | Train Loss 1.0899 Acc 0.9227 | Val Loss 1.0534 Acc 0.9482 | LR 5.00e-04\n",
      "Epoch 043 | Train Loss 1.0912 Acc 0.9217 | Val Loss 1.0912 Acc 0.9217 | LR 5.00e-04\n",
      "Epoch 044 | Train Loss 1.0879 Acc 0.9233 | Val Loss 1.0493 Acc 0.9486 | LR 5.00e-04\n",
      "Epoch 045 | Train Loss 1.0872 Acc 0.9240 | Val Loss 1.0872 Acc 0.9240 | LR 5.00e-04\n",
      "Epoch 046 | Train Loss 1.0866 Acc 0.9252 | Val Loss 1.0476 Acc 0.9516 | LR 5.00e-04\n",
      "Epoch 047 | Train Loss 1.0875 Acc 0.9244 | Val Loss 1.0875 Acc 0.9244 | LR 5.00e-04\n",
      "Epoch 048 | Train Loss 1.0854 Acc 0.9257 | Val Loss 1.0432 Acc 0.9511 | LR 5.00e-04\n",
      "Epoch 049 | Train Loss 1.0838 Acc 0.9266 | Val Loss 1.0838 Acc 0.9266 | LR 5.00e-04\n",
      "Epoch 050 | Train Loss 1.0817 Acc 0.9277 | Val Loss 1.0446 Acc 0.9538 | LR 5.00e-04\n",
      "Epoch 051 | Train Loss 1.0823 Acc 0.9284 | Val Loss 1.0823 Acc 0.9284 | LR 5.00e-04\n",
      "Epoch 052 | Train Loss 1.0851 Acc 0.9261 | Val Loss 1.0424 Acc 0.9549 | LR 5.00e-04\n",
      "Epoch 053 | Train Loss 1.0853 Acc 0.9255 | Val Loss 1.0853 Acc 0.9255 | LR 5.00e-04\n",
      "Epoch 054 | Train Loss 1.0842 Acc 0.9256 | Val Loss 1.0363 Acc 0.9577 | LR 5.00e-04\n",
      "Epoch 055 | Train Loss 1.0847 Acc 0.9259 | Val Loss 1.0847 Acc 0.9259 | LR 5.00e-04\n",
      "Epoch 056 | Train Loss 1.0868 Acc 0.9248 | Val Loss 1.0425 Acc 0.9537 | LR 5.00e-04\n",
      "Epoch 057 | Train Loss 1.0894 Acc 0.9236 | Val Loss 1.0894 Acc 0.9236 | LR 5.00e-04\n",
      "Epoch 058 | Train Loss 1.0866 Acc 0.9243 | Val Loss 1.0399 Acc 0.9571 | LR 5.00e-04\n",
      "Epoch 059 | Train Loss 1.0818 Acc 0.9287 | Val Loss 1.0818 Acc 0.9287 | LR 5.00e-04\n",
      "Epoch 060 | Train Loss 1.0800 Acc 0.9292 | Val Loss 1.0384 Acc 0.9578 | LR 5.00e-04\n",
      "Epoch 061 | Train Loss 1.0777 Acc 0.9309 | Val Loss 1.0777 Acc 0.9309 | LR 5.00e-04\n",
      "Epoch 062 | Train Loss 1.0776 Acc 0.9309 | Val Loss 1.0330 Acc 0.9605 | LR 5.00e-04\n",
      "Epoch 063 | Train Loss 1.0777 Acc 0.9304 | Val Loss 1.0777 Acc 0.9304 | LR 5.00e-04\n",
      "Epoch 064 | Train Loss 1.0794 Acc 0.9299 | Val Loss 1.0384 Acc 0.9568 | LR 5.00e-04\n",
      "Epoch 065 | Train Loss 1.0802 Acc 0.9300 | Val Loss 1.0802 Acc 0.9300 | LR 5.00e-04\n",
      "Epoch 066 | Train Loss 1.0757 Acc 0.9329 | Val Loss 1.0346 Acc 0.9588 | LR 5.00e-04\n",
      "Epoch 067 | Train Loss 1.0779 Acc 0.9300 | Val Loss 1.0779 Acc 0.9300 | LR 5.00e-04\n",
      "Epoch 068 | Train Loss 1.0767 Acc 0.9316 | Val Loss 1.0332 Acc 0.9613 | LR 5.00e-04\n",
      "Epoch 069 | Train Loss 1.0773 Acc 0.9307 | Val Loss 1.0773 Acc 0.9307 | LR 5.00e-04\n",
      "Epoch 070 | Train Loss 1.0805 Acc 0.9282 | Val Loss 1.0334 Acc 0.9600 | LR 5.00e-04\n",
      "Epoch 071 | Train Loss 1.0759 Acc 0.9322 | Val Loss 1.0759 Acc 0.9322 | LR 5.00e-04\n",
      "Epoch 072 | Train Loss 1.0754 Acc 0.9325 | Val Loss 1.0338 Acc 0.9595 | LR 5.00e-04\n",
      "Epoch 073 | Train Loss 1.0724 Acc 0.9343 | Val Loss 1.0724 Acc 0.9343 | LR 5.00e-04\n",
      "Epoch 074 | Train Loss 1.0737 Acc 0.9325 | Val Loss 1.0250 Acc 0.9616 | LR 5.00e-04\n",
      "Epoch 075 | Train Loss 1.0746 Acc 0.9326 | Val Loss 1.0746 Acc 0.9326 | LR 5.00e-04\n",
      "Epoch 076 | Train Loss 1.0716 Acc 0.9342 | Val Loss 1.0282 Acc 0.9621 | LR 5.00e-04\n",
      "Epoch 077 | Train Loss 1.0742 Acc 0.9327 | Val Loss 1.0742 Acc 0.9327 | LR 5.00e-04\n",
      "Epoch 078 | Train Loss 1.0725 Acc 0.9339 | Val Loss 1.0250 Acc 0.9642 | LR 5.00e-04\n",
      "Epoch 079 | Train Loss 1.0721 Acc 0.9338 | Val Loss 1.0721 Acc 0.9338 | LR 5.00e-04\n",
      "Epoch 080 | Train Loss 1.0729 Acc 0.9337 | Val Loss 1.0222 Acc 0.9653 | LR 5.00e-04\n",
      "Epoch 081 | Train Loss 1.0691 Acc 0.9353 | Val Loss 1.0691 Acc 0.9353 | LR 5.00e-04\n",
      "Epoch 082 | Train Loss 1.0673 Acc 0.9358 | Val Loss 1.0308 Acc 0.9622 | LR 5.00e-04\n",
      "Epoch 083 | Train Loss 1.0675 Acc 0.9366 | Val Loss 1.0675 Acc 0.9366 | LR 5.00e-04\n",
      "Epoch 084 | Train Loss 1.0654 Acc 0.9380 | Val Loss 1.0255 Acc 0.9663 | LR 5.00e-04\n",
      "Epoch 085 | Train Loss 1.0649 Acc 0.9378 | Val Loss 1.0649 Acc 0.9378 | LR 5.00e-04\n",
      "Epoch 086 | Train Loss 1.0663 Acc 0.9374 | Val Loss 1.0194 Acc 0.9676 | LR 5.00e-04\n",
      "Epoch 087 | Train Loss 1.0630 Acc 0.9386 | Val Loss 1.0630 Acc 0.9386 | LR 5.00e-04\n",
      "Epoch 088 | Train Loss 1.0629 Acc 0.9385 | Val Loss 1.0269 Acc 0.9619 | LR 5.00e-04\n",
      "Epoch 089 | Train Loss 1.0645 Acc 0.9376 | Val Loss 1.0645 Acc 0.9376 | LR 5.00e-04\n",
      "Epoch 090 | Train Loss 1.0624 Acc 0.9391 | Val Loss 1.0183 Acc 0.9663 | LR 5.00e-04\n",
      "Epoch 091 | Train Loss 1.0606 Acc 0.9404 | Val Loss 1.0606 Acc 0.9404 | LR 5.00e-04\n",
      "Epoch 092 | Train Loss 1.0588 Acc 0.9408 | Val Loss 1.0143 Acc 0.9677 | LR 5.00e-04\n",
      "Epoch 093 | Train Loss 1.0584 Acc 0.9407 | Val Loss 1.0584 Acc 0.9407 | LR 5.00e-04\n",
      "Epoch 094 | Train Loss 1.0545 Acc 0.9432 | Val Loss 1.0163 Acc 0.9684 | LR 5.00e-04\n",
      "Epoch 095 | Train Loss 1.0567 Acc 0.9422 | Val Loss 1.0567 Acc 0.9422 | LR 5.00e-04\n",
      "Epoch 096 | Train Loss 1.0583 Acc 0.9406 | Val Loss 1.0172 Acc 0.9679 | LR 5.00e-04\n",
      "Epoch 097 | Train Loss 1.0583 Acc 0.9418 | Val Loss 1.0583 Acc 0.9418 | LR 5.00e-04\n",
      "Epoch 098 | Train Loss 1.0595 Acc 0.9398 | Val Loss 1.0148 Acc 0.9703 | LR 5.00e-04\n",
      "Epoch 099 | Train Loss 1.0617 Acc 0.9391 | Val Loss 1.0617 Acc 0.9391 | LR 5.00e-04\n",
      "Epoch 100 | Train Loss 1.0593 Acc 0.9408 | Val Loss 1.0090 Acc 0.9698 | LR 5.00e-04\n",
      "Epoch 101 | Train Loss 1.0600 Acc 0.9406 | Val Loss 1.0600 Acc 0.9406 | LR 5.00e-04\n",
      "Epoch 102 | Train Loss 1.0548 Acc 0.9426 | Val Loss 1.0104 Acc 0.9712 | LR 5.00e-04\n",
      "Epoch 103 | Train Loss 1.0548 Acc 0.9429 | Val Loss 1.0548 Acc 0.9429 | LR 5.00e-04\n",
      "Epoch 104 | Train Loss 1.0528 Acc 0.9439 | Val Loss 1.0145 Acc 0.9683 | LR 5.00e-04\n",
      "Epoch 105 | Train Loss 1.0571 Acc 0.9415 | Val Loss 1.0571 Acc 0.9415 | LR 5.00e-04\n",
      "Epoch 106 | Train Loss 1.0522 Acc 0.9435 | Val Loss 1.0119 Acc 0.9711 | LR 5.00e-04\n",
      "Epoch 107 | Train Loss 1.0528 Acc 0.9437 | Val Loss 1.0528 Acc 0.9437 | LR 5.00e-04\n",
      "Epoch 108 | Train Loss 1.0564 Acc 0.9411 | Val Loss 1.0149 Acc 0.9690 | LR 5.00e-04\n",
      "Epoch 109 | Train Loss 1.0563 Acc 0.9406 | Val Loss 1.0563 Acc 0.9406 | LR 5.00e-04\n",
      "Epoch 110 | Train Loss 1.0566 Acc 0.9421 | Val Loss 1.0046 Acc 0.9731 | LR 5.00e-04\n",
      "Epoch 111 | Train Loss 1.0533 Acc 0.9440 | Val Loss 1.0533 Acc 0.9440 | LR 5.00e-04\n",
      "Epoch 112 | Train Loss 1.0564 Acc 0.9410 | Val Loss 1.0162 Acc 0.9703 | LR 5.00e-04\n",
      "Epoch 113 | Train Loss 1.0590 Acc 0.9400 | Val Loss 1.0590 Acc 0.9400 | LR 5.00e-04\n",
      "Epoch 114 | Train Loss 1.0591 Acc 0.9397 | Val Loss 1.0086 Acc 0.9713 | LR 5.00e-04\n",
      "Epoch 115 | Train Loss 1.0550 Acc 0.9419 | Val Loss 1.0550 Acc 0.9419 | LR 5.00e-04\n",
      "Epoch 116 | Train Loss 1.0564 Acc 0.9422 | Val Loss 1.0082 Acc 0.9720 | LR 5.00e-04\n",
      "Epoch 117 | Train Loss 1.0568 Acc 0.9414 | Val Loss 1.0568 Acc 0.9414 | LR 5.00e-04\n",
      "Epoch 118 | Train Loss 1.0560 Acc 0.9413 | Val Loss 1.0120 Acc 0.9682 | LR 5.00e-04\n",
      "Epoch 119 | Train Loss 1.0552 Acc 0.9422 | Val Loss 1.0552 Acc 0.9422 | LR 5.00e-04\n",
      "Epoch 120 | Train Loss 1.0552 Acc 0.9421 | Val Loss 1.0123 Acc 0.9715 | LR 5.00e-04\n",
      "Epoch 121 | Train Loss 1.0541 Acc 0.9421 | Val Loss 1.0541 Acc 0.9421 | LR 5.00e-04\n",
      "Epoch 122 | Train Loss 1.0550 Acc 0.9422 | Val Loss 1.0075 Acc 0.9725 | LR 2.50e-04\n",
      "Epoch 123 | Train Loss 1.0500 Acc 0.9451 | Val Loss 1.0500 Acc 0.9451 | LR 5.00e-04\n",
      "Epoch 124 | Train Loss 1.0549 Acc 0.9420 | Val Loss 1.0065 Acc 0.9730 | LR 5.00e-04\n",
      "Epoch 125 | Train Loss 1.0569 Acc 0.9414 | Val Loss 1.0569 Acc 0.9414 | LR 5.00e-04\n",
      "Early stopping triggered.\n",
      "Best model (val_loss=1.0046) saved to results/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "from hrm import HRMTrainer, HRMConfig, HierarchicalReasoningModel, ModelConfig\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "hrm_config = HRMConfig(\n",
    "    input_dim=1,   # Each position has 1 feature (digit value) - input is (B, 81, 1)\n",
    "    output_dim=10, # 10 possible values (0-9) for each position\n",
    "    hidden_dim=256, \n",
    "    num_layers=8,\n",
    "    dropout=0.1,\n",
    "    N=6,  \n",
    "    T=16   \n",
    ")\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    learning_rate=5e-4,\n",
    "    batch_size=64,\n",
    "    max_epochs=300,\n",
    "    embeddings_lr=0.002,\n",
    "    weight_decay=1e-4  \n",
    ")\n",
    "\n",
    "model = HierarchicalReasoningModel(config=hrm_config, device=device)\n",
    "\n",
    "trainer = HRMTrainer(model, config=model_config, device=device)\n",
    "\n",
    "train_dataset = sudoku.SudokuDataset(puzzles, solutions)\n",
    "val_dataset = sudoku.SudokuDataset(test_puzzles, test_solutions)\n",
    "\n",
    "trainer.train(train_dataset, val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39112ab5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb67b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Puzzle:\n",
      "[4, 0, 0, 0, 0, 8, 1, 0, 0]\n",
      "[6, 1, 0, 0, 0, 0, 9, 7, 5]\n",
      "[0, 7, 2, 1, 5, 6, 0, 8, 0]\n",
      "[1, 4, 0, 6, 8, 0, 5, 0, 7]\n",
      "[2, 0, 7, 9, 0, 0, 0, 1, 4]\n",
      "[5, 9, 6, 4, 7, 1, 0, 2, 0]\n",
      "[0, 0, 9, 8, 6, 4, 7, 0, 0]\n",
      "[7, 5, 0, 3, 0, 0, 8, 4, 6]\n",
      "[8, 0, 4, 5, 1, 7, 0, 3, 0]\n",
      "Predicted Solution:\n",
      "[np.int64(4), np.int64(3), np.int64(5), np.int64(7), np.int64(9), np.int64(8), np.int64(1), np.int64(6), np.int64(2)]\n",
      "[np.int64(6), np.int64(1), np.int64(8), np.int64(2), np.int64(4), np.int64(3), np.int64(9), np.int64(7), np.int64(5)]\n",
      "[np.int64(9), np.int64(7), np.int64(2), np.int64(1), np.int64(5), np.int64(6), np.int64(4), np.int64(8), np.int64(3)]\n",
      "[np.int64(1), np.int64(4), np.int64(3), np.int64(6), np.int64(8), np.int64(2), np.int64(5), np.int64(9), np.int64(7)]\n",
      "[np.int64(2), np.int64(8), np.int64(7), np.int64(9), np.int64(3), np.int64(5), np.int64(6), np.int64(1), np.int64(4)]\n",
      "[np.int64(5), np.int64(9), np.int64(6), np.int64(4), np.int64(7), np.int64(1), np.int64(3), np.int64(2), np.int64(8)]\n",
      "[np.int64(3), np.int64(2), np.int64(9), np.int64(8), np.int64(6), np.int64(4), np.int64(7), np.int64(5), np.int64(1)]\n",
      "[np.int64(7), np.int64(5), np.int64(1), np.int64(3), np.int64(2), np.int64(9), np.int64(8), np.int64(4), np.int64(6)]\n",
      "[np.int64(8), np.int64(6), np.int64(4), np.int64(5), np.int64(1), np.int64(7), np.int64(2), np.int64(3), np.int64(9)]\n",
      "True Solution:\n",
      "[np.int64(4), np.int64(3), np.int64(5), np.int64(7), np.int64(9), np.int64(8), np.int64(1), np.int64(6), np.int64(2)]\n",
      "[np.int64(6), np.int64(1), np.int64(8), np.int64(2), np.int64(4), np.int64(3), np.int64(9), np.int64(7), np.int64(5)]\n",
      "[np.int64(9), np.int64(7), np.int64(2), np.int64(1), np.int64(5), np.int64(6), np.int64(4), np.int64(8), np.int64(3)]\n",
      "[np.int64(1), np.int64(4), np.int64(3), np.int64(6), np.int64(8), np.int64(2), np.int64(5), np.int64(9), np.int64(7)]\n",
      "[np.int64(2), np.int64(8), np.int64(7), np.int64(9), np.int64(3), np.int64(5), np.int64(6), np.int64(1), np.int64(4)]\n",
      "[np.int64(5), np.int64(9), np.int64(6), np.int64(4), np.int64(7), np.int64(1), np.int64(3), np.int64(2), np.int64(8)]\n",
      "[np.int64(3), np.int64(2), np.int64(9), np.int64(8), np.int64(6), np.int64(4), np.int64(7), np.int64(5), np.int64(1)]\n",
      "[np.int64(7), np.int64(5), np.int64(1), np.int64(3), np.int64(2), np.int64(9), np.int64(8), np.int64(4), np.int64(6)]\n",
      "[np.int64(8), np.int64(6), np.int64(4), np.int64(5), np.int64(1), np.int64(7), np.int64(2), np.int64(3), np.int64(9)]\n",
      "Cell Accuracy: 1.0000\n",
      "Valid Sudoku: True\n",
      "\n",
      "=== Sudoku Validation Results ===\n",
      "Total samples validated: 10\n",
      "Valid Sudoku solutions: 2\n",
      "Sudoku validity rate: 0.2000 (20.00%)\n",
      "Average cell accuracy: 0.9728 (97.28%)\n"
     ]
    }
   ],
   "source": [
    "def validate_sudoku_predictions(model, dataset, num_samples=10):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    def is_valid_sudoku(grid):\n",
    "        \n",
    "        for row in grid:\n",
    "            if len(set(row)) != 9 or not all(1 <= x <= 9 for x in row):\n",
    "                return False\n",
    "        \n",
    "        # Check columns\n",
    "        for col in range(9):\n",
    "            column = [grid[row][col] for row in range(9)]\n",
    "            if len(set(column)) != 9:\n",
    "                return False\n",
    "        \n",
    "        # Check 3x3 boxes\n",
    "        for box_row in range(3):\n",
    "            for box_col in range(3):\n",
    "                box = []\n",
    "                for r in range(3):\n",
    "                    for c in range(3):\n",
    "                        box.append(grid[box_row*3 + r][box_col*3 + c])\n",
    "                if len(set(box)) != 9:\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def calculate_cell_accuracy(predicted, target):\n",
    "        return (predicted == target).float().mean().item()\n",
    "    \n",
    "    # Sample validation data\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    results = {\n",
    "        'valid_sudokus': 0,\n",
    "        'total_samples': 0,\n",
    "        'cell_accuracies': [],\n",
    "        'sudoku_validity_rate': 0.0,\n",
    "        'average_cell_accuracy': 0.0\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            puzzle, solution = batch[\"puzzle\"], batch[\"solution\"]\n",
    "            puzzle = puzzle.to(device)#.float()\n",
    "            solution = solution.to(device).long()\n",
    "            \n",
    "            # Get model prediction\n",
    "            #if puzzle.dim() == 2:\n",
    "            #    puzzle = puzzle.unsqueeze(-1)  # Add feature dimension\n",
    "            \n",
    "            output = model(puzzle)  # Shape: (1, 81, 10)\n",
    "            predicted = output.argmax(dim=-1)  # Shape: (1, 81)\n",
    "            \n",
    "            # Convert to numpy and reshape to 9x9\n",
    "            pred_grid = predicted.cpu().numpy()[0].reshape(9, 9)\n",
    "            true_grid = solution.cpu().numpy()[0].reshape(9, 9)\n",
    "            \n",
    "            # Calculate cell accuracy\n",
    "            cell_acc = calculate_cell_accuracy(predicted[0], solution[0])\n",
    "            results['cell_accuracies'].append(cell_acc)\n",
    "            \n",
    "            # Check if prediction is valid sudoku\n",
    "            is_valid = is_valid_sudoku(pred_grid)\n",
    "            if is_valid:\n",
    "                results['valid_sudokus'] += 1\n",
    "            \n",
    "            results['total_samples'] += 1\n",
    "            \n",
    "            # Print first few examples\n",
    "            if i < 1:\n",
    "                print(f\"\\nSample {i+1}:\")\n",
    "                print(\"Puzzle:\")\n",
    "                puzzle_display = puzzle.cpu().numpy()[0].reshape(9, 9)\n",
    "                for row in puzzle_display:\n",
    "                    print([int(x) for x in row])\n",
    "                \n",
    "                print(\"Predicted Solution:\")\n",
    "                for row in pred_grid:\n",
    "                    print(list(row))\n",
    "                \n",
    "                print(\"True Solution:\")\n",
    "                for row in true_grid:\n",
    "                    print(list(row))\n",
    "                \n",
    "                print(f\"Cell Accuracy: {cell_acc:.4f}\")\n",
    "                print(f\"Valid Sudoku: {is_valid}\")\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    results['sudoku_validity_rate'] = results['valid_sudokus'] / results['total_samples']\n",
    "    results['average_cell_accuracy'] = sum(results['cell_accuracies']) / len(results['cell_accuracies'])\n",
    "    \n",
    "    print(f\"\\n=== Sudoku Validation Results ===\")\n",
    "    print(f\"Total samples validated: {results['total_samples']}\")\n",
    "    print(f\"Valid Sudoku solutions: {results['valid_sudokus']}\")\n",
    "    print(f\"Sudoku validity rate: {results['sudoku_validity_rate']:.4f} ({results['sudoku_validity_rate']*100:.2f}%)\")\n",
    "    print(f\"Average cell accuracy: {results['average_cell_accuracy']:.4f} ({results['average_cell_accuracy']*100:.2f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run validation\n",
    "validation_results = validate_sudoku_predictions(model, val_dataset, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a76d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from epoch 110 with val_loss 1.0046\n",
      "\n",
      "=== Comprehensive Model Evaluation on 1000 Test Games ===\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and evaluate on 100 test samples\n",
    "#best_checkpoint = torch.load('results/best_model.pt', map_location=device)\n",
    "#model.load_state_dict(best_checkpoint['model'])\n",
    "print(f\"Loaded best model from epoch {best_checkpoint['epoch']} with val_loss {best_checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "total_games = 1000  \n",
    "# Create a subset of test dataset with 100 samples\n",
    "test_subset_puzzles = test_puzzles[:total_games]\n",
    "test_subset_solutions = test_solutions[:total_games]\n",
    "test_subset_dataset = sudoku.SudokuDataset(test_subset_puzzles, test_subset_solutions)\n",
    "\n",
    "# Comprehensive evaluation\n",
    "print(f\"\\n=== Comprehensive Model Evaluation on {total_games} Test Games ===\")\n",
    "\n",
    "# 1. Basic accuracy evaluation using trainer\n",
    "test_loss, test_acc = trainer.evaluate(test_subset_dataset)\n",
    "\n",
    "# 2. Detailed Sudoku validation\n",
    "detailed_results = validate_sudoku_predictions(model, test_subset_dataset, num_samples=1000)\n",
    "\n",
    "# 3. Summary statistics\n",
    "print(f\"\\n=== Final Results Summary ===\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Valid Sudoku Solutions: {detailed_results['valid_sudokus']}/100 ({detailed_results['sudoku_validity_rate']*100:.2f}%)\")\n",
    "print(f\"Average Cell Accuracy: {detailed_results['average_cell_accuracy']:.4f} ({detailed_results['average_cell_accuracy']*100:.2f}%)\")\n",
    "\n",
    "# 4. Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a comprehensive results visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training curves\n",
    "ax1.plot(trainer.train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(trainer.val_losses, label='Validation Loss', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(trainer.train_accuracies, label='Train Accuracy', color='blue')\n",
    "ax2.plot(trainer.val_accuracies, label='Validation Accuracy', color='red')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Cell accuracy distribution\n",
    "ax3.hist(detailed_results['cell_accuracies'], bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "ax3.set_xlabel('Cell Accuracy')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Distribution of Cell Accuracies (100 Test Games)')\n",
    "ax3.axvline(detailed_results['average_cell_accuracy'], color='red', linestyle='--', \n",
    "           label=f'Mean: {detailed_results[\"average_cell_accuracy\"]:.3f}')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Summary metrics bar chart\n",
    "metrics = ['Test Accuracy', 'Cell Accuracy', 'Sudoku Validity Rate']\n",
    "values = [test_acc * 100, detailed_results['average_cell_accuracy'] * 100, \n",
    "          detailed_results['sudoku_validity_rate'] * 100]\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "bars = ax4.bar(metrics, values, color=colors, edgecolor='black', alpha=0.8)\n",
    "ax4.set_ylabel('Percentage (%)')\n",
    "ax4.set_title('Model Performance Summary')\n",
    "ax4.set_ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, values):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/model_evaluation_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Additional detailed accuracy analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Cell accuracy vs sample number\n",
    "sample_numbers = range(1, len(detailed_results['cell_accuracies']) + 1)\n",
    "ax1.plot(sample_numbers, detailed_results['cell_accuracies'], 'o-', alpha=0.7, color='blue')\n",
    "ax1.axhline(detailed_results['average_cell_accuracy'], color='red', linestyle='--', \n",
    "           label=f'Average: {detailed_results[\"average_cell_accuracy\"]:.3f}')\n",
    "ax1.set_xlabel('Test Sample Number')\n",
    "ax1.set_ylabel('Cell Accuracy')\n",
    "ax1.set_title('Cell Accuracy per Test Sample')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance comparison chart\n",
    "categories = ['Perfect Sudokus', 'Invalid Sudokus']\n",
    "counts = [detailed_results['valid_sudokus'], detailed_results['total_samples'] - detailed_results['valid_sudokus']]\n",
    "colors = ['green', 'red']\n",
    "\n",
    "print(f\"Valid sudokus: {counts[0]}, Invalid sudokus: {counts[1]}\")\n",
    "\n",
    "ax2.pie(counts, labels=categories, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title(f'Sudoku Solution Validity ({sum(counts)} Test Games)')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(f\"\\nGraphs saved to 'results/model_evaluation_results.png' and 'results/detailed_accuracy_analysis.png'\")\n",
    "plt.savefig('results/detailed_accuracy_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed2d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
