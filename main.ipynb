{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b548c12",
   "metadata": {},
   "source": [
    "trying to implement the HRM model architecture\n",
    "\n",
    "\n",
    "Input layer:\n",
    "- Puzzle embedding and sequence embedding\n",
    "\n",
    "deep supervision\n",
    "- runs the input and y_true from the dataloader\n",
    "- run one HRM block\n",
    "- find loss from cross entropyu\n",
    "- train / backprop\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914ca90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path_data = \"./data/sudoku-extreme-1k-aug-1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3add1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Metadata:\n",
      "  pad_id: 0\n",
      "  ignore_label_id: 0\n",
      "  blank_identifier_id: 0\n",
      "  vocab_size: 11\n",
      "  seq_len: 81\n",
      "  num_puzzle_identifiers: 1\n",
      "  total_groups: 1000\n",
      "  mean_puzzle_examples: 1.0\n",
      "  sets: ['all']\n",
      "\n",
      "Identifiers: ['<blank>']\n",
      "\n",
      "Dataset Shapes:\n",
      "  Inputs: (1001000, 81)\n",
      "  Labels: (1001000, 81)\n",
      "  Puzzle IDs: (1001000,)\n",
      "  Puzzle Indices: (1001001,)\n",
      "  Group Indices: (1001,)\n",
      "\n",
      "Data Types:\n",
      "  Inputs: int64\n",
      "  Labels: int64\n",
      "  Puzzle IDs: int32\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Load dataset metadata\n",
    "with open(f\"{path_data}/train/dataset.json\", \"r\") as f:\n",
    "    dataset_metadata = json.load(f)\n",
    "\n",
    "with open(f\"{path_data}/identifiers.json\", \"r\") as f:\n",
    "    identifiers = json.load(f)\n",
    "\n",
    "print(\"Dataset Metadata:\")\n",
    "for key, value in dataset_metadata.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nIdentifiers: {identifiers}\")\n",
    "\n",
    "# Load dataset arrays\n",
    "train_inputs = np.load(f\"{path_data}/train/all__inputs.npy\")\n",
    "train_labels = np.load(f\"{path_data}/train/all__labels.npy\")\n",
    "train_puzzle_ids = np.load(f\"{path_data}/train/all__puzzle_identifiers.npy\")\n",
    "train_puzzle_indices = np.load(f\"{path_data}/train/all__puzzle_indices.npy\")\n",
    "train_group_indices = np.load(f\"{path_data}/train/all__group_indices.npy\")\n",
    "\n",
    "print(f\"\\nDataset Shapes:\")\n",
    "print(f\"  Inputs: {train_inputs.shape}\")\n",
    "print(f\"  Labels: {train_labels.shape}\")\n",
    "print(f\"  Puzzle IDs: {train_puzzle_ids.shape}\")\n",
    "print(f\"  Puzzle Indices: {train_puzzle_indices.shape}\")\n",
    "print(f\"  Group Indices: {train_group_indices.shape}\")\n",
    "\n",
    "print(f\"\\nData Types:\")\n",
    "print(f\"  Inputs: {train_inputs.dtype}\")\n",
    "print(f\"  Labels: {train_labels.dtype}\")\n",
    "print(f\"  Puzzle IDs: {train_puzzle_ids.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9abee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST 10 SUDOKU PUZZLES IN DATASET\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "PUZZLE 1\n",
      "Group Index: 0\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ 1 _ _ 5 _ _ 8 _    0| 6 1 4 2 5 7 3 8 9\n",
      "1| _ _ _ _ _ _ _ _ 2    1| 5 8 7 3 9 1 6 4 2\n",
      "2| 9 _ _ 4 _ _ 7 _ _    2| 9 2 3 4 6 8 7 1 5\n",
      "3| _ 7 _ 6 _ _ 1 _ _    3| 8 7 5 6 2 9 1 3 4\n",
      "4| 1 _ _ 7 8 _ _ 5 _    4| 1 3 9 7 8 4 2 5 6\n",
      "5| _ _ 6 _ _ 3 _ _ _    5| 2 4 6 5 1 3 8 9 7\n",
      "6| 7 9 _ _ _ _ _ 2 _    6| 7 9 8 1 4 6 5 2 3\n",
      "7| _ _ 1 9 _ _ 4 _ _    7| 3 5 1 9 7 2 4 6 8\n",
      "8| 4 _ _ _ 3 _ _ _ _    8| 4 6 2 8 3 5 9 7 1\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 2\n",
      "Group Index: 1001\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ 3 _ _ 8 5 2 _ _    0| 1 3 9 7 8 5 2 4 6\n",
      "1| 5 _ _ _ _ 2 _ _ 3    1| 5 7 8 4 6 2 9 1 3\n",
      "2| _ _ 6 3 _ _ _ _ _    2| 4 2 6 3 9 1 7 5 8\n",
      "3| 6 5 _ 2 _ _ 8 _ _    3| 6 5 4 2 1 3 8 7 9\n",
      "4| _ 1 _ _ 7 _ _ _ 4    4| 9 1 3 5 7 8 6 2 4\n",
      "5| _ _ 7 _ _ _ _ _ _    5| 2 8 7 9 4 6 1 3 5\n",
      "6| _ 4 _ _ _ 9 _ _ 1    6| 7 4 2 6 5 9 3 8 1\n",
      "7| _ _ _ _ _ _ _ 9 _    7| 8 6 5 1 3 7 4 9 2\n",
      "8| 3 _ _ 8 _ _ 5 _ _    8| 3 9 1 8 2 4 5 6 7\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 3\n",
      "Group Index: 2002\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ 4 _ _ 8 _ _ 1    0| 6 2 4 5 3 8 9 7 1\n",
      "1| _ 5 _ 7 _ _ 3 _ _    1| 8 5 1 7 9 2 3 6 4\n",
      "2| _ _ _ _ 1 _ _ _ _    2| 7 3 9 4 1 6 8 5 2\n",
      "3| _ _ 5 6 _ _ _ 3 7    3| 1 8 5 6 4 9 2 3 7\n",
      "4| _ 7 _ _ _ 5 _ _ 6    4| 3 7 2 1 8 5 4 9 6\n",
      "5| 9 _ _ _ _ _ 5 _ _    5| 9 4 6 2 7 3 5 1 8\n",
      "6| 2 _ _ _ _ _ _ _ _    6| 2 6 3 8 5 7 1 4 9\n",
      "7| _ _ 8 _ _ 4 _ 2 _    7| 5 1 8 9 6 4 7 2 3\n",
      "8| _ 9 7 3 _ _ 6 _ _    8| 4 9 7 3 2 1 6 8 5\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 4\n",
      "Group Index: 3003\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ -4 -4 -4 -4 -4 -4 -2 -4    0| 0 3 1 -3 -1 4 5 -2 2\n",
      "1| -4 5 -4 -4 2 -4 4 -4 -3    1| -1 5 -2 0 2 3 4 1 -3\n",
      "2| -4 -4 -3 -4 -4 5 -4 -4 _    2| 2 4 -3 1 -2 5 3 -1 0\n",
      "3| -4 -4 -4 3 -4 -4 -4 -4 -4    3| -3 2 4 3 1 0 -1 5 -2\n",
      "4| -4 -1 -4 -4 -4 -3 -4 -4 1    4| -2 -1 3 2 5 -3 0 4 1\n",
      "5| -4 -4 5 -4 4 -4 2 -4 -4    5| 1 0 5 -1 4 -2 2 -3 3\n",
      "6| -4 1 -4 -4 -4 -4 -2 -4 -4    6| 3 1 0 5 -3 -1 -2 2 4\n",
      "7| 5 -4 -4 -4 -4 1 -4 -4 -1    7| 5 -2 2 4 0 1 -3 3 -1\n",
      "8| -4 -3 -1 -4 3 -4 -4 -4 -4    8| 4 -3 -1 -2 3 2 1 0 5\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 5\n",
      "Group Index: 4004\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ _ _ 4 _ _ _ _    0| 7 5 8 2 4 3 1 9 6\n",
      "1| _ _ 1 9 _ _ _ 5 _    1| 4 6 1 9 8 7 3 5 2\n",
      "2| 2 _ _ _ _ 6 8 _ _    2| 2 9 3 5 1 6 8 4 7\n",
      "3| _ 7 _ _ _ _ _ _ 3    3| 1 7 5 8 6 9 4 2 3\n",
      "4| 3 _ _ _ _ 5 _ 6 _    4| 3 8 4 7 2 5 9 6 1\n",
      "5| 6 _ 9 1 _ _ 5 _ _    5| 6 2 9 1 3 4 5 7 8\n",
      "6| _ _ 7 _ _ _ 2 _ _    6| 9 1 7 6 5 8 2 3 4\n",
      "7| _ _ _ 4 _ _ 6 8 _    7| 5 3 2 4 7 1 6 8 9\n",
      "8| 8 _ _ _ _ 2 _ _ 5    8| 8 4 6 3 9 2 7 1 5\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 6\n",
      "Group Index: 5005\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ _ _ _ 7 _ _ _    0| 2 3 1 8 9 7 4 5 6\n",
      "1| 4 _ _ 1 _ _ _ 9 _    1| 4 7 5 1 6 2 8 9 3\n",
      "2| _ 6 _ _ 3 _ 2 _ _    2| 8 6 9 5 3 4 2 7 1\n",
      "3| 9 _ _ _ _ _ 5 _ _    3| 9 8 7 4 1 6 5 3 2\n",
      "4| 1 4 _ _ 7 _ _ _ _    4| 1 4 3 2 7 5 9 6 8\n",
      "5| _ _ 6 9 _ _ _ 4 _    5| 5 2 6 9 8 3 1 4 7\n",
      "6| _ _ 8 _ _ _ _ _ 5    6| 7 9 8 3 4 1 6 2 5\n",
      "7| _ 1 _ 6 _ _ _ 8 _    7| 3 1 2 6 5 9 7 8 4\n",
      "8| 6 _ _ _ 2 _ 3 1 _    8| 6 5 4 7 2 8 3 1 9\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 7\n",
      "Group Index: 6006\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ 3 6 _ _ 9 _ 8    0| 7 5 3 6 2 1 9 4 8\n",
      "1| _ 6 _ _ 8 _ _ _ 7    1| 4 6 2 9 8 3 5 1 7\n",
      "2| _ _ _ _ _ 7 _ 2 _    2| 8 9 1 5 4 7 6 2 3\n",
      "3| 5 _ _ _ _ _ _ _ _    3| 5 7 4 3 9 8 1 6 2\n",
      "4| _ _ 9 _ 6 _ 3 _ _    4| 1 2 9 7 6 4 3 8 5\n",
      "5| _ 8 _ 1 _ _ _ _ 4    5| 3 8 6 1 5 2 7 9 4\n",
      "6| _ _ _ 4 _ _ 2 _ _    6| 6 1 8 4 7 5 2 3 9\n",
      "7| _ _ 5 8 1 _ _ _ _    7| 2 3 5 8 1 9 4 7 6\n",
      "8| _ 4 _ _ _ 6 _ _ 1    8| 9 4 7 2 3 6 8 5 1\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 8\n",
      "Group Index: 7007\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ 9 _ 6 _ _ _ 5 _    0| 1 9 4 6 3 2 7 5 8\n",
      "1| _ _ 2 _ 1 _ 3 _ _    1| 8 5 2 7 1 4 3 9 6\n",
      "2| _ _ _ _ _ 9 _ _ _    2| 3 7 6 8 5 9 2 4 1\n",
      "3| 7 _ _ 5 _ _ _ 6 _    3| 7 2 1 5 4 8 9 6 3\n",
      "4| _ _ 8 _ 2 _ 4 1 _    4| 6 3 8 9 2 7 4 1 5\n",
      "5| _ _ _ _ _ _ _ _ 7    5| 5 4 9 1 6 3 8 2 7\n",
      "6| _ 8 _ 3 _ _ 1 _ _    6| 4 8 5 3 9 6 1 7 2\n",
      "7| 2 1 _ _ 8 _ _ 3 _    7| 2 1 7 4 8 5 6 3 9\n",
      "8| _ _ 3 _ _ _ _ _ 4    8| 9 6 3 2 7 1 5 8 4\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 9\n",
      "Group Index: 8008\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ 3 _ _ _ 9 _ _    0| 4 6 3 5 8 1 9 7 2\n",
      "1| 9 _ _ _ 6 _ _ _ 1    1| 9 7 5 3 6 2 4 8 1\n",
      "2| 1 8 _ 4 _ _ _ 6 _    2| 1 8 2 4 7 9 5 6 3\n",
      "3| 2 _ _ _ 1 _ _ 5 _    3| 2 9 8 6 1 4 3 5 7\n",
      "4| _ _ _ _ _ 7 _ _ _    4| 3 5 6 2 9 7 1 4 8\n",
      "5| _ 4 _ 8 _ _ _ _ 6    5| 7 4 1 8 3 5 2 9 6\n",
      "6| 5 _ _ _ 2 _ 6 _ _    6| 5 1 7 9 2 8 6 3 4\n",
      "7| _ _ _ 7 _ _ _ 1 5    7| 6 2 9 7 4 3 8 1 5\n",
      "8| _ 3 _ _ _ _ _ 2 _    8| 8 3 4 1 5 6 7 2 9\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "PUZZLE 10\n",
      "Group Index: 9009\n",
      "Puzzle ID: 0\n",
      "==================================================\n",
      "\n",
      "INPUT (_ = blank)        SOLUTION\n",
      "  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\n",
      "  -----------------      -----------------\n",
      "0| _ _ _ _ _ _ 7 _ _    0| 4 1 5 3 9 8 7 2 6\n",
      "1| _ _ 7 _ _ 5 _ 9 _    1| 2 8 7 6 4 5 3 9 1\n",
      "2| _ 6 _ _ 2 _ _ 8 4    2| 3 6 9 7 2 1 5 8 4\n",
      "3| 6 _ _ _ _ 3 _ _ 8    3| 6 5 4 9 1 3 2 7 8\n",
      "4| 8 _ 2 _ 6 _ _ 3 _    4| 8 7 2 5 6 4 1 3 9\n",
      "5| _ 3 _ _ _ _ 4 _ _    5| 9 3 1 8 7 2 4 6 5\n",
      "6| 1 _ _ _ _ 9 _ 5 _    6| 1 4 8 2 3 9 6 5 7\n",
      "7| _ _ _ 1 _ _ _ _ _    7| 7 9 3 1 5 6 8 4 2\n",
      "8| _ 2 _ _ 8 _ _ _ 3    8| 5 2 6 4 8 7 9 1 3\n",
      "\n",
      "Statistics: 81 filled, 0 blank cells\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def display_puzzle_pair(idx, input_puzzle, solution_puzzle):\n",
    "    \"\"\"Display input and solution side by side\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"PUZZLE {idx + 1}\")\n",
    "    print(f\"Group Index: {train_group_indices[idx]}\")\n",
    "    print(f\"Puzzle ID: {train_puzzle_ids[idx]}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Convert to grids\n",
    "    input_grid = input_puzzle.reshape(9, 9)\n",
    "    solution_grid = solution_puzzle.reshape(9, 9)\n",
    "    \n",
    "    print(\"\\nINPUT (_ = blank)        SOLUTION\")\n",
    "    print(\"  0 1 2 3 4 5 6 7 8      0 1 2 3 4 5 6 7 8\")\n",
    "    print(\"  -----------------      -----------------\")\n",
    "\n",
    "    pad_id = dataset_metadata[\"pad_id\"] # from datajson file\n",
    "    pad = input_puzzle[pad_id] # position of the pad\n",
    "    for i in range(9):\n",
    "        # Input row\n",
    "        input_row = f\"{i}|\"\n",
    "        \n",
    "        for val in input_grid[i]:\n",
    "            val -= pad\n",
    "            if val == 0:\n",
    "                input_row += \" _\"\n",
    "            else:\n",
    "                input_row += f\" {val}\"\n",
    "        \n",
    "        # Solution row\n",
    "        solution_row = f\"    {i}|\"\n",
    "        for val in solution_grid[i]:\n",
    "            val -= pad\n",
    "            solution_row += f\" {val}\"\n",
    "            \n",
    "        print(input_row + solution_row)\n",
    "    \n",
    "    # Count filled vs blank cells\n",
    "    filled_cells = np.sum(input_puzzle != 0)\n",
    "    blank_cells = np.sum(input_puzzle == 0)\n",
    "    print(f\"\\nStatistics: {filled_cells} filled, {blank_cells} blank cells\")\n",
    "\n",
    "# Display first 10 puzzles\n",
    "print(\"FIRST 10 SUDOKU PUZZLES IN DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(min(10, len(train_inputs))):\n",
    "    display_puzzle_pair(i, train_inputs[i], train_labels[i])\n",
    "    \n",
    "    # Add a small separator between puzzles\n",
    "    if i < 9:\n",
    "        print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING SUDOKU DATALOADERS\n",
      "==================================================\n",
      "Loaded train dataset:\n",
      "  Samples: 1001000\n",
      "  Input shape: torch.Size([1001000, 81])\n",
      "  Label shape: torch.Size([1001000, 81])\n",
      "  Vocab size: 11\n",
      "  Sequence length: 81\n",
      "Loaded train dataset:\n",
      "  Samples: 1001000\n",
      "  Input shape: torch.Size([1001000, 81])\n",
      "  Label shape: torch.Size([1001000, 81])\n",
      "  Vocab size: 11\n",
      "  Sequence length: 81\n",
      "Loaded test dataset:\n",
      "  Samples: 422786\n",
      "  Input shape: torch.Size([422786, 81])\n",
      "  Label shape: torch.Size([422786, 81])\n",
      "  Vocab size: 11\n",
      "  Sequence length: 81\n",
      "Test dataset loaded with 422786 samples\n",
      "\n",
      "DataLoader Summary:\n",
      "  Training batches: 25025\n",
      "  Validation batches: 6257\n",
      "  Test batches: 13213\n",
      "\n",
      "Testing DataLoaders:\n",
      "------------------------------\n",
      "Loaded test dataset:\n",
      "  Samples: 422786\n",
      "  Input shape: torch.Size([422786, 81])\n",
      "  Label shape: torch.Size([422786, 81])\n",
      "  Vocab size: 11\n",
      "  Sequence length: 81\n",
      "Test dataset loaded with 422786 samples\n",
      "\n",
      "DataLoader Summary:\n",
      "  Training batches: 25025\n",
      "  Validation batches: 6257\n",
      "  Test batches: 13213\n",
      "\n",
      "Testing DataLoaders:\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'SudokuDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 209\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# Get a sample batch from training loader\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample Training Batch:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    211\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch[\u001b[33m'\u001b[39m\u001b[33minput\u001b[39m\u001b[33m'\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:493\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:424\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1171\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1164\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/hrm/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from typing import Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "\n",
    "class SudokuDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Sudoku puzzles optimized for machine learning training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str, split: str = \"train\", transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the Sudoku dataset\n",
    "        \n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load metadata\n",
    "        self._load_metadata()\n",
    "        \n",
    "        # Load data\n",
    "        self._load_data()\n",
    "        \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load metadata from dataset.json\"\"\"\n",
    "        metadata_path = f\"{self.data_path}/{self.split}/dataset.json\"\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "            \n",
    "        self.pad_id = metadata[\"pad_id\"]\n",
    "        self.blank_identifier_id = metadata[\"blank_identifier_id\"]\n",
    "        self.vocab_size = metadata[\"vocab_size\"]\n",
    "        self.seq_len = metadata[\"seq_len\"]\n",
    "        self.ignore_label_id = metadata.get(\"ignore_label_id\", 0)\n",
    "        \n",
    "    def _load_data(self):\n",
    "        \"\"\"Load the numpy arrays and convert to tensors\"\"\"\n",
    "        split_path = f\"{self.data_path}/{self.split}\"\n",
    "        \n",
    "        # Load and convert to PyTorch tensors\n",
    "        self.inputs = torch.from_numpy(np.load(f\"{split_path}/all__inputs.npy\")).long()\n",
    "        self.labels = torch.from_numpy(np.load(f\"{split_path}/all__labels.npy\")).long()\n",
    "        self.puzzle_ids = torch.from_numpy(np.load(f\"{split_path}/all__puzzle_identifiers.npy\")).long()\n",
    "        self.group_indices = torch.from_numpy(np.load(f\"{split_path}/all__group_indices.npy\")).long()\n",
    "        \n",
    "        print(f\"Loaded {self.split} dataset:\")\n",
    "        print(f\"  Samples: {len(self.inputs)}\")\n",
    "        print(f\"  Input shape: {self.inputs.shape}\")\n",
    "        print(f\"  Label shape: {self.labels.shape}\")\n",
    "        print(f\"  Vocab size: {self.vocab_size}\")\n",
    "        print(f\"  Sequence length: {self.seq_len}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single sample from the dataset\n",
    "        \n",
    "        Returns:\n",
    "            Dict with input, target, and metadata\n",
    "        \"\"\"\n",
    "        sample = {\n",
    "            'input': self.inputs[idx],           # Shape: (81,) - flattened 9x9 grid\n",
    "            'target': self.labels[idx],          # Shape: (81,) - solution grid\n",
    "            'puzzle_id': self.puzzle_ids[idx],   # Puzzle identifier\n",
    "            'group_id': self.group_indices[idx], # Group identifier\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        \"\"\"Return dataset metadata\"\"\"\n",
    "        return {\n",
    "            'pad_id': self.pad_id,\n",
    "            'blank_identifier_id': self.blank_identifier_id,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'seq_len': self.seq_len,\n",
    "            'ignore_label_id': self.ignore_label_id\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for batching Sudoku samples\n",
    "    \n",
    "    Args:\n",
    "        batch: List of samples from SudokuDataset\n",
    "        \n",
    "    Returns:\n",
    "        Batched tensors\n",
    "    \"\"\"\n",
    "    inputs = torch.stack([item['input'] for item in batch])\n",
    "    targets = torch.stack([item['target'] for item in batch])\n",
    "    puzzle_ids = torch.stack([item['puzzle_id'] for item in batch])\n",
    "    group_ids = torch.stack([item['group_id'] for item in batch])\n",
    "    \n",
    "    return {\n",
    "        'input': inputs,      # Shape: (batch_size, 81)\n",
    "        'target': targets,    # Shape: (batch_size, 81)\n",
    "        'puzzle_id': puzzle_ids,  # Shape: (batch_size,)\n",
    "        'group_id': group_ids,    # Shape: (batch_size,)\n",
    "    }\n",
    "\n",
    "def create_dataloaders(data_path: str, \n",
    "                      batch_size: int = 32,\n",
    "                      train_split: float = 0.8,\n",
    "                      val_split: float = 0.2,\n",
    "                      num_workers: int = 2,\n",
    "                      shuffle: bool = True) -> Tuple[DataLoader, DataLoader, Optional[DataLoader]]:\n",
    "    \"\"\"\n",
    "    Create train, validation, and test dataloaders\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load training dataset\n",
    "    train_dataset = SudokuDataset(data_path, split=\"train\")\n",
    "    \n",
    "    # Split train dataset into train/validation\n",
    "    total_size = len(train_dataset)\n",
    "    train_size = int(train_split * total_size)\n",
    "    val_size = total_size - train_size\n",
    "    \n",
    "    train_subset, val_subset = random_split(\n",
    "        train_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    # Try to load test dataset\n",
    "    test_loader = None\n",
    "    try:\n",
    "        test_dataset = SudokuDataset(data_path, split=\"test\")\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            collate_fn=collate_fn,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        print(f\"Test dataset loaded with {len(test_dataset)} samples\")\n",
    "    except:\n",
    "        print(\"No test dataset found, using only train/validation split\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Create the dataloaders\n",
    "print(\"CREATING SUDOKU DATALOADERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    data_path=path_data,\n",
    "    batch_size=32,\n",
    "    train_split=0.8,\n",
    "    val_split=0.2,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoader Summary:\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "if test_loader:\n",
    "    print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test the dataloaders\n",
    "print(f\"\\nTesting DataLoaders:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Get a sample batch from training loader\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    print(f\"Sample Training Batch:\")\n",
    "    print(f\"  Input shape: {batch['input'].shape}\")\n",
    "    print(f\"  Target shape: {batch['target'].shape}\")\n",
    "    print(f\"  Input dtype: {batch['input'].dtype}\")\n",
    "    print(f\"  Target dtype: {batch['target'].dtype}\")\n",
    "    print(f\"  Puzzle IDs: {batch['puzzle_id'][:5]}...\")  # Show first 5\n",
    "    print(f\"  Input range: [{batch['input'].min().item()}, {batch['input'].max().item()}]\")\n",
    "    print(f\"  Target range: [{batch['target'].min().item()}, {batch['target'].max().item()}]\")\n",
    "    break\n",
    "\n",
    "# Display a sample from the batch\n",
    "sample_input = batch['input'][0].numpy().reshape(9, 9)\n",
    "sample_target = batch['target'][0].numpy().reshape(9, 9)\n",
    "\n",
    "print(f\"\\nSample Puzzle from Batch:\")\n",
    "print(\"INPUT (0=blank):\")\n",
    "print(sample_input)\n",
    "print(\"\\nTARGET (solution):\")\n",
    "print(sample_target)\n",
    "\n",
    "# Get dataset metadata\n",
    "dataset = SudokuDataset(path_data, split=\"train\")\n",
    "metadata = dataset.get_metadata()\n",
    "print(f\"\\nDataset Metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nDataLoaders ready for machine learning training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
